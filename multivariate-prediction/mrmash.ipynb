{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Multivariate prediction workflow\n",
    "\n",
    "This notebook applies mrmash on data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "RDS format of a list of objects, in which case you can specify the names of objects corresponding to the quantities `X`, `Y`, etc. Optionally univariate summary statistics information are provided to compute scaling factor of the prior (summary statistics will be computed on the fly if not provided).\n",
    "\n",
    "**FIXME: need to document the input data structure**\n",
    "**Also for prior files should they be stored similarly with data for each fold as `fold_??` tables**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis unit we output:\n",
    "\n",
    "1. Analysis results in RDS format\n",
    "2. Default visualization plots\n",
    "\n",
    "**FIXME: at this point we dont have output figure yet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Analysis examples\n",
    "\n",
    "**FIXME: please adjust the command arguments to use mr-mash data**\n",
    "\n",
    "```\n",
    "sos run mrmash.ipynb complete_data_analysis \\\n",
    "    --analysis-units data/27_brain_non_brain_genes_v8.txt \\\n",
    "    --data-dir /project2/compbio/GTEx_eQTL/cis_eqtl_analysis_ready \\\n",
    "    --data-suffix GTEx_V8.rds \\\n",
    "    --name 20210409 \\\n",
    "    --wd /project2/compbio/GTEx_eQTL/mvSuSiE_output/cis_results \\\n",
    "    --prior /project2/compbio/GTEx_eQTL/mvSuSiE_output/GTEx_V8_strong_z.teem.rds \\\n",
    "    --sample-partition /project/mstephens/fmorgante/mr_mash_test/data/gtex-v8-ids-folds.txt \\\n",
    "    -c midway2.yml -q midway2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import glob\n",
    "# single column file each line is the data filename\n",
    "parameter: analysis_units = path\n",
    "# Path to data directory\n",
    "parameter: data_dir = path\n",
    "# data file suffix\n",
    "parameter: data_suffix = str\n",
    "# Path to work directory where output locates\n",
    "parameter: wd = path(\"./output\")\n",
    "# Path to prior data file: an RDS file with `U` and `w` for prior matrices and weights\n",
    "parameter: prior = path('.')\n",
    "# Path to residual cor/cov data file\n",
    "parameter: resid_cor = path('.')\n",
    "# Path to summary statistics directory\n",
    "parameter: sumstats_dir = path\n",
    "# An identifier for your run of analysis\n",
    "parameter: name = str\n",
    "# Only analyze `cis` variants -- cis = N means using N variants around the center column of X matrix  \n",
    "parameter: cis = 'NULL'\n",
    "regions = [x.strip() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "genes = [f\"{data_dir:a}/{x}.{data_suffix}\" for x in regions if path(f\"{data_dir:a}/{x}.{data_suffix}\").exists()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[complete_data_analysis_1]\n",
    "parameter: sample_partition = path\n",
    "parameter: fold = 1\n",
    "# remove a variant if it has more than imiss missing individual data\n",
    "parameter: imiss = 0.05\n",
    "parameter: maf = 0.05\n",
    "parameter: var_cutoff = 0.05\n",
    "parameter: nthreads = 1\n",
    "parameter: n_nonmiss_Y = 100\n",
    "parameter: canonical_mats = \"FALSE\"\n",
    "parameter: standardize = \"TRUE\"\n",
    "parameter: w0_init = \"NULL\"\n",
    "parameter: update_w0 = \"TRUE\"\n",
    "parameter: w0_threshold = 0.0\n",
    "parameter: update_V = \"TRUE\"\n",
    "parameter: update_V_method = \"full\"\n",
    "parameter: B_init_method = \"enet\"\n",
    "parameter: max_iter = 5000\n",
    "parameter: tol = 1e-2\n",
    "parameter: verbose = \"FALSE\"\n",
    "parameter: save_model = \"TRUE\"\n",
    "parameter: glmnet_pred = \"TRUE\"\n",
    "parameter: sumstats = path(\".\")\n",
    "input: genes, group_by = 1\n",
    "output: f'{wd:a}/fold_{fold}/{_input:bn}_{name}.rds'\n",
    "task: trunk_workers = 1, trunk_size = 18, walltime = '2h', mem = '10G', cores = nthreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output[0]:nn}.stdout\", stderr = f\"{_output[0]:nn}.stderr\"\n",
    "\n",
    "    options(stringsAsFactors = FALSE)\n",
    "\n",
    "    set.seed(1)\n",
    "\n",
    "    ###Set some parameter variables (These should be set in the SoS script)\n",
    "    fold <- ${fold}\n",
    "    nthreads <- ${nthreads}\n",
    "    missing_rate_cutoff <- ${imiss}\n",
    "    maf_cutoff <- ${maf}\n",
    "    var_cutoff <- ${var_cutoff}\n",
    "    n_nonmiss_Y <- ${n_nonmiss_Y}\n",
    "    canonical_mats <- ${canonical_mats}\n",
    "    standardize <- ${standardize}\n",
    "    w0_init <- ${w0_init}\n",
    "    update_w0 <- ${update_w0}\n",
    "    w0_threshold <- ${w0_threshold}\n",
    "    update_V <- ${update_V}\n",
    "    update_V_method <- \"${update_V_method}\"\n",
    "    B_init_method <- \"${B_init_method}\"\n",
    "    max_iter <- ${max_iter}\n",
    "    tol <- ${tol}\n",
    "    verbose <- ${verbose}\n",
    "    save_model <- ${save_model}\n",
    "    glmnet_pred <- ${glmnet_pred}\n",
    "\n",
    "    ###Functions to compute MAF, missing genotype rate, impute missing, and filter X accordingly \n",
    "    compute_maf <- function(geno){\n",
    "      f <- mean(geno,na.rm = TRUE)/2\n",
    "      return(min(f, 1-f))\n",
    "    }\n",
    "\n",
    "    compute_missing <- function(geno){\n",
    "      miss <- sum(is.na(geno))/length(geno)\n",
    "      return(miss)\n",
    "    }\n",
    "\n",
    "    compute_non_missing_y <- function(y){\n",
    "      nonmiss <- sum(!is.na(y))\n",
    "      return(nonmiss)\n",
    "    }\n",
    "\n",
    "    mean_impute <- function(geno){\n",
    "      f <- apply(geno, 2, function(x) mean(x,na.rm = TRUE))\n",
    "      for (i in 1:length(f)) geno[,i][which(is.na(geno[,i]))] <- f[i]\n",
    "      return(geno)\n",
    "    }\n",
    "\n",
    "    filter_X <- function(X, missing_rate_thresh, maf_thresh, var_thresh) {\n",
    "      rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      rm_col <- which(apply(X, 2, compute_maf) < maf_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      X <- mean_impute(X)\n",
    "      rm_col <- which(matrixStats::colVars(X) < var_thresh)\n",
    "      if (length(rm_col)) X <- X[, -rm_col]\n",
    "      return(X)\n",
    "    }\n",
    "\n",
    "    filter_Y <- function(Y, n_nonmiss){\n",
    "      rm_col <- which(apply(Y, 2, compute_non_missing_y) < n_nonmiss)\n",
    "      if (length(rm_col)) Y <- Y[, -rm_col]\n",
    "      return(Y)\n",
    "    }\n",
    "\n",
    "    ###Function to compute the grid\n",
    "    autoselect_mixsd <- function(data, mult=2){\n",
    "      include <- !(data$Shat==0 | !is.finite(data$Shat) | is.na(data$Bhat))\n",
    "      gmax <- grid_max(data$Bhat[include], data$Shat[include])\n",
    "      gmin <- grid_min(data$Bhat[include], data$Shat[include])\n",
    "      if (mult == 0) {\n",
    "        return(c(0, gmax/2))\n",
    "      }\n",
    "      else {\n",
    "        npoint = ceiling(log2(gmax/gmin)/log2(mult))\n",
    "        return(mult^((-npoint):0) * gmax)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    ###Compute the minimum value for the grid\n",
    "    grid_min = function(Bhat,Shat){\n",
    "      min(Shat)\n",
    "    }\n",
    "\n",
    "    ###Compute the maximum value for the grid\n",
    "    grid_max = function(Bhat,Shat){\n",
    "      if (all(Bhat^2 <= Shat^2)) {\n",
    "        8 * grid_min(Bhat,Shat) # the unusual case where we don't need much grid\n",
    "      }  else {\n",
    "        2 * sqrt(max(Bhat^2 - Shat^2))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    ###Function to compute initial estimates of the coefficients from group-lasso\n",
    "    compute_coefficients_glasso <- function(X, Y, standardize, nthreads, Xnew=NULL, version=c(\"Rcpp\", \"R\")){\n",
    "\n",
    "      version <- match.arg(version)\n",
    "\n",
    "      n <- nrow(X)\n",
    "      p <- ncol(X)\n",
    "      r <- ncol(Y)\n",
    "      Y_has_missing <- any(is.na(Y))\n",
    "      tissue_names <- colnames(Y)\n",
    "\n",
    "      if(Y_has_missing){\n",
    "        ###Extract per-individual Y missingness patterns\n",
    "        Y_miss_patterns <- mr.mash.alpha:::extract_missing_Y_pattern(Y)\n",
    "\n",
    "        ###Compute V and its inverse\n",
    "        V <- mr.mash.alpha:::compute_V_init(X, Y, matrix(0, p, r), method=\"flash\")\n",
    "        Vinv <- chol2inv(chol(V))\n",
    "\n",
    "        ###Initialize missing Ys\n",
    "        muy <- colMeans(Y, na.rm=TRUE)\n",
    "        for(l in 1:r){\n",
    "          Y[is.na(Y[, l]), l] <- muy[l]\n",
    "        }\n",
    "\n",
    "        ###Compute expected Y (assuming B=0)\n",
    "        mu <- matrix(rep(muy, each=n), n, r)\n",
    "\n",
    "        ###Impute missing Ys \n",
    "        Y <- mr.mash.alpha:::impute_missing_Y(Y=Y, mu=mu, Vinv=Vinv, miss=Y_miss_patterns$miss, non_miss=Y_miss_patterns$non_miss, \n",
    "                                              version=version)$Y\n",
    "      }\n",
    "\n",
    "      ##Fit group-lasso\n",
    "      if(nthreads>1){\n",
    "        doMC::registerDoMC(nthreads)\n",
    "        paral <- TRUE\n",
    "      } else {\n",
    "        paral <- FALSE\n",
    "      }\n",
    "\n",
    "      cvfit_glmnet <- glmnet::cv.glmnet(x=X, y=Y, family=\"mgaussian\", alpha=1, standardize=standardize, parallel=paral)\n",
    "      coeff_glmnet <- coef(cvfit_glmnet, s=\"lambda.min\")\n",
    "\n",
    "      ##Build matrix of initial estimates for mr.mash\n",
    "      B <- matrix(as.numeric(NA), nrow=p, ncol=r)\n",
    "\n",
    "      for(i in 1:length(coeff_glmnet)){\n",
    "        B[, i] <- as.vector(coeff_glmnet[[i]])[-1]\n",
    "      }\n",
    "\n",
    "      ##Make predictions if requested\n",
    "      if(!is.null(Xnew)){\n",
    "        Yhat_glmnet <- drop(predict(cvfit_glmnet, newx=Xnew, s=\"lambda.min\"))\n",
    "        colnames(Yhat_glmnet) <- tissue_names\n",
    "        res <- list(Bhat=B, Ytrain=Y, Yhat_new=Yhat_glmnet)\n",
    "      } else {\n",
    "        res <- list(Bhat=B, Ytrain=Y)\n",
    "      }\n",
    "\n",
    "      return(res)\n",
    "    }\n",
    "\n",
    "    compute_coefficients_univ_glmnet <- function(X, Y, alpha, standardize, nthreads, Xnew=NULL){\n",
    "\n",
    "      r <- ncol(Y)\n",
    "\n",
    "      linreg <- function(i, X, Y, alpha, standardize, nthreads, Xnew){\n",
    "        if(nthreads>1){\n",
    "          doMC::registerDoMC(nthreads)\n",
    "          paral <- TRUE\n",
    "        } else {\n",
    "          paral <- FALSE\n",
    "        }\n",
    "\n",
    "        samples_kept <- which(!is.na(Y[, i]))\n",
    "        Ynomiss <- Y[samples_kept, i]\n",
    "        Xnomiss <- X[samples_kept, ]\n",
    "\n",
    "        cvfit <- glmnet::cv.glmnet(x=Xnomiss, y=Ynomiss, family=\"gaussian\", alpha=alpha, standardize=standardize, parallel=paral)\n",
    "        coeffic <- as.vector(coef(cvfit, s=\"lambda.min\"))\n",
    "        lambda_seq <- cvfit$lambda\n",
    "\n",
    "        ##Make predictions if requested\n",
    "        if(!is.null(Xnew)){\n",
    "          yhat_glmnet <- drop(predict(cvfit, newx=Xnew, s=\"lambda.min\"))\n",
    "          res <- list(bhat=coeffic, lambda_seq=lambda_seq, yhat_new=yhat_glmnet)\n",
    "        } else {\n",
    "          res <- list(bhat=coeffic, lambda_seq=lambda_seq)\n",
    "        }\n",
    "\n",
    "        return(res)\n",
    "      }\n",
    "\n",
    "      out <- lapply(1:r, linreg, X, Y, alpha, standardize, nthreads, Xnew)\n",
    "\n",
    "      Bhat <- sapply(out,\"[[\",\"bhat\")\n",
    "\n",
    "      if(!is.null(Xnew)){\n",
    "        Yhat_new <- sapply(out,\"[[\",\"yhat_new\")\n",
    "        colnames(Yhat_new) <- colnames(Y)\n",
    "        results <- list(Bhat=Bhat[-1, ], intercept=Bhat[1, ], Yhat_new=Yhat_new)\n",
    "      } else {\n",
    "        results <- list(Bhat=Bhat[-1, ], intercept=Bhat[1, ])\n",
    "      }\n",
    "\n",
    "      return(results)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    ###Read in the data\n",
    "    dat <- readRDS(${_input:r})\n",
    "    tryCatch({\n",
    "    sumstats <- readRDS(\"${sumstats_dir}/${_input:bn}_sumstats_cv.rds\")\n",
    "    }, error = function(e) {\n",
    "      # FIXME: we can implement it and provide a warning instead\n",
    "      stop(\"Computing summary stats on the fly is not yet implemented. Please provide proper summary stats path\")\n",
    "    })\n",
    "    tryCatch({\n",
    "    datadriven_mats <- readRDS(${prior:r})\n",
    "      }, error = function(e) {\n",
    "      # FIXME: we can implement it and provide a warning instead\n",
    "      stop(\"Default prior is not yet implemented. Please provide a prior to use\")\n",
    "    })\n",
    "    gtex_ids_folds <- read.table(${sample_partition:r}, header=TRUE, sep=\"\\t\")\n",
    "\n",
    "    ###Extract sumstats and only for specified fold\n",
    "    fold_name <- paste0(\"fold_\", fold)\n",
    "    sumstats <- sumstats[fold_name]\n",
    "\n",
    "    ###Extract and filter Y and X\n",
    "    Y <- filter_Y(dat$y_res, n_nonmiss_Y)\n",
    "    X <- filter_X(dat$X, missing_rate_cutoff, maf_cutoff, var_cutoff)\n",
    "\n",
    "    ###Drop tissues with < n_nonmiss_Y in data-driven matrices and sumstats\n",
    "    tissues_to_keep <- colnames(Y)\n",
    "    #Handle different data structure between udr and Bovy's ed\n",
    "    if(!is.list(datadriven_mats$U[[1]])){\n",
    "      S0_data <- lapply(datadriven_mats$U, function(x, to_keep){x[to_keep, to_keep]}, tissues_to_keep)\n",
    "    } else {\n",
    "      S0_data <- lapply(datadriven_mats$U, function(x, to_keep){x$mat[to_keep, to_keep]}, tissues_to_keep)\n",
    "    }\n",
    "    sumstats <- lapply(sumstats[[1]], function(x, to_keep){x[, to_keep]}, tissues_to_keep)\n",
    "\n",
    "    ###Split the data in training and test sets\n",
    "    test_ids <- gtex_ids_folds[which(gtex_ids_folds$fold == fold), \"id\"]\n",
    "    Xtrain <- X[!(rownames(X) %in% test_ids), ]\n",
    "    Ytrain <- Y[!(rownames(Y) %in% test_ids), ]\n",
    "    Xtest <- X[test_ids, ]\n",
    "    Ytest <- Y[test_ids, ]\n",
    "\n",
    "    ###Compute canonical matrices, if requested\n",
    "    if(canonical_mats){\n",
    "      S0_can <- mr.mash.alpha::compute_canonical_covs(ncol(Ytrain), singletons=TRUE, hetgrid=c(0, 0.25, 0.5, 0.75, 1))\n",
    "      S0_raw <- c(S0_can, S0_data)\n",
    "    } else {\n",
    "      S0_raw <- S0_data\n",
    "    }\n",
    "\n",
    "    ###Compute prior covariance\n",
    "    grid <- autoselect_mixsd(sumstats, mult=sqrt(2))^2\n",
    "    S0 <- mr.mash.alpha::expand_covs(S0_raw, grid, zeromat=TRUE)\n",
    "\n",
    "    time1 <- proc.time()\n",
    "\n",
    "    ###Compute initial estimates of regression coefficients and prior weights (if not provided)\n",
    "    if(glmnet_pred){\n",
    "      Xnew <- Xtest\n",
    "    } else {\n",
    "      Xnew <- NULL\n",
    "    }\n",
    "\n",
    "    if(B_init_method == \"enet\"){\n",
    "      out <- compute_coefficients_univ_glmnet(Xtrain, Ytrain, alpha=0.5, standardize=standardize, nthreads=nthreads, Xnew=Xnew)\n",
    "    } else if(B_init_method == \"glasso\"){\n",
    "      out <- compute_coefficients_glasso(Xtrain, Ytrain, standardize=standardize, nthreads=nthreads, Xnew=Xnew)\n",
    "    }\n",
    "\n",
    "    if(is.null(w0_init)){\n",
    "      prop_nonzero_glmnet <- sum(rowSums(abs(out$Bhat))>0)/ncol(Xtrain)\n",
    "      w0 <- c((1-prop_nonzero_glmnet), rep(prop_nonzero_glmnet/(length(S0)-1), (length(S0)-1)))\n",
    "    } else {\n",
    "      w0 <- w0_init\n",
    "    }\n",
    "\n",
    "    ###Fit mr.mash\n",
    "    fit_mrmash <- mr.mash.alpha::mr.mash(X=Xtrain, Y=Ytrain, S0=S0, w0=w0, update_w0=update_w0, tol=tol,\n",
    "                          max_iter=max_iter, convergence_criterion=\"ELBO\", compute_ELBO=TRUE,  \n",
    "                          standardize=standardize, verbose=verbose, update_V=update_V, update_V_method=update_V_method,\n",
    "                          w0_threshold=w0_threshold, nthreads=nthreads, mu1_init=out$Bhat)\n",
    "\n",
    "    time2 <- proc.time()\n",
    "\n",
    "    elapsed_time <- time2[\"elapsed\"] - time1[\"elapsed\"]\n",
    "\n",
    "    ###Compute column sums of the posterior assignment probabilities\n",
    "    w1_colsums <- colSums(fit_mrmash$w1)\n",
    "    if(w0_threshold > 0){\n",
    "      tmp <- rep(0, length(S0))\n",
    "      names(tmp) <- names(S0)\n",
    "      tmp[which(names(tmp) %in% names(w1_colsums))] <- w1_colsums\n",
    "      w1_colsums <- tmp\n",
    "    }\n",
    "\n",
    "    ###Make predictions\n",
    "    Yhat_test <- predict(fit_mrmash, Xtest)\n",
    "\n",
    "    ###Save results\n",
    "    resu <- list(w1_colsums=w1_colsums, Ytest=Ytest, Yhat_test=Yhat_test, elapsed_time=elapsed_time)\n",
    "    if(save_model){\n",
    "     resu$model <-  fit_mrmash\n",
    "    }\n",
    "\n",
    "    if(glmnet_pred){\n",
    "      resu$Yhat_test_glmnet <- out$Yhat_new\n",
    "    }\n",
    "\n",
    "    saveRDS(resu, ${_output[0]:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
