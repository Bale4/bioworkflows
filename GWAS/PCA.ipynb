{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Principal component analysis\n",
    "\n",
    "The intention of this notebook is to perform the PCA analysis on genotype data and generate plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "Steps to generate a PCA include \n",
    "\n",
    "- removing related individuals\n",
    "- pruning variants in linkage disequilibrium (LD)\n",
    "- perform PCA analysis on genotype\n",
    "- excluding outlier samples in the PCA space for individuals of homogeneous self-reported ancestry. These outliers may suggest poor genotyping quality or distant relatedness.\n",
    "\n",
    "Pitfalls\n",
    "\n",
    "1. Some of the PCs may capture LD structure rather than population structure (decrease in power to detect associations in these regions of high LD)\n",
    "2. When projecting a new study dataset to the PCA space computed from a reference dataset: projected PCs are shrunk toward 0 in the new dataset\n",
    "3. PC scores may capture outliers that are due to family structure, population structure or other reasons; it might be beneficial to detect and remove these individuals to maximize the population structure captured by PCA (in the case of removing a few outliers) or to restrict analyses to genetically homogeneous samples\n",
    "\n",
    "## Input\n",
    "\n",
    "1. `bfile` in PLINK format (`.bed`, `.bim` and `.fam`): the genotype array to calculate individual relationship as well as to perform PCA (when `genoFile` is not provided)\n",
    "2. genoFile in PLINK format: could be different from bfile in the case of using for e.g. exome data/ imputed genotype data\n",
    "3. relatedness file (you can calculate relatedness beforehand, using PLINK 2 which implements the KING algorithm)\n",
    "\n",
    "## Output\n",
    "\n",
    "Form the kinship analysis\n",
    "1. Kinship table\n",
    "\n",
    "From the PCA analysis\n",
    "1. eigen values / singular values\n",
    "2. eigen vectors\n",
    "3. projection (PC's)\n",
    "4. loadings\n",
    "5. scale\n",
    "6. mahalanobis distances for outlier removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## General workflow\n",
    "\n",
    "1. Estimate relatedness of the individuals in the sample by PLINK 2 that implements the KING algorithm\n",
    "2. Select specific SNPs and samples using PLINK (QC maf>1%, geno missing rate (`geno`) 0.1, individual missing rate (`mind`) =0.1 and `hwe`=5e-08) \n",
    "3. SNPs thining by doing LD-pruning (window=50, shift=10, r2=0.1 are the defaults) and remove related individuals prior to PCA calculation\n",
    "4. First PCA run using only unrelated individuals\n",
    "5. Calculate mahalanobis distance per population and create outlier removal file. Default criteria is 6 SD from the mean but we recommend checking the output plot before and after removal and rethink about it.\n",
    "6. Re-calculate PC's without outliers\n",
    "7. Project related samples to the PC space\n",
    "8. Second round of outlier removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Method\n",
    "\n",
    "Here is a quick recap of PCA analysis for those not immediately familiar with the method. PCA is a mathematical method to reduce dimensionality of the data while retaining most of the variation in the dataset. \n",
    "This is accomplished by identifying directions or Principal Components (PC's) that account for the maximum variation in the data. \n",
    "\n",
    "One common approach to PCA is based on the singular-value decomposition of the the data matrix $X$ (in our case the genotype matrix),\n",
    "$$X = U D V^T,$$\n",
    "where $U$ are the left eigenvectors, $D$ is the diagonal matrix of singular values, and $V$ are the right eigenvectors (also called loadings). \n",
    "\n",
    "PCA can also be done using the eigen-decomposition of $X X^T$\n",
    "$$X X^T = U S U^T,$$ where $S=D^2$ is the diagonal matrix of eigenvalues.\n",
    "$X$ is usually centred (mean-subtracted) or standardised (mean subtracted, then divided by standard deviation) before PCA.\n",
    "\n",
    "For PCA of SNP genotypes (at least in diploid organisms), the common standardisation is\n",
    "$$X_{ij}^{\\prime} = \\frac{X_{ij} - 2p_j}{\\sqrt{2 p_j (1 - p_j)}},$$\n",
    "where $X_{ij}$ is the genotype (minor allele dosage $\\{0, 1, 2\\}$) for the $i$th individual and the $j$th SNP, and $p_j$ is the minor allele frequency (MAF) for the $j$th SNP. In addition, the eigenvalues are scaled by the number of SNPs $m$ (equivalent to performing the eigen-decomposition of $XX^T/m$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## How to run this workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "A minimal working example can be [obtained here](https://drive.google.com/drive/folders/15gpOTi7RKFnDYuiHbY5-F-n2GeLx2ZZt?usp=sharing).\n",
    "\n",
    "FIXME: have to show people how to run the GWAS QC step, then the actual PCA workflow. Also have to perhaps do this multiple runs to reflect the iterative procedure 1 - 8 listed above. You can also fix the narratives below that i recycled from the QC pipeline specific to PCA context.\n",
    "\n",
    "**Notice: there is no notion of steps in the pipeline definition; rather the steps below will be modular and you call them here with different steps. That is, your MWE demo will be running a few `sos` commands as different steps**\n",
    "\n",
    "\n",
    "FIXME: Diana I cannot get the MWE work out of the box so I'll leave all my edits untested, and I'll rely on you to iron out edges\n",
    "\n",
    "```\n",
    "ERROR: Function named_output can only be used in input or depends statements\n",
    "```\n",
    "\n",
    "is the error message I get when I download the MWE and run the command.\n",
    "\n",
    "\n",
    "### Step 1: Estimate kinship in the sample\n",
    "Aim: identify and remove closely related individuals prior to PCA analysis.\n",
    "\n",
    "\n",
    "### Step 2 and 3: QC the genetic data \n",
    "\n",
    "- Step 2: QC based on MAF, sample and variant missigness and Hardy-Weinberg Equilibrium. You can provide a list of samples to keep, for example in the case when you would like to subset a sample based on their ancestries to perform independent analyses on each of these groups.\n",
    "- Step 3: In this step you have to prune SNPs in linkage dissequilibrium to make sure the PCA actually captures population structure and not LD structure (which could reduce the power of detecting genetic associations in these LD-regions). Also, related individuals are removed to generate the cleaned bfile to use in PCA calculations\n",
    "\n",
    "### Step 4: PCA analysis\n",
    "\n",
    "### Step 5: Generate bed file with outliers removed for 2nd round of PCA\n",
    "\n",
    "### Step 6: Do second round of PCA\n",
    "\n",
    "### Step 7: Project related individuals\n",
    "\n",
    "### Step 8: Remove outliers\n",
    "\n",
    "```\n",
    "sos run ~/project/bioworkflows/GWAS/PCA.ipynb flashpca \\\n",
    "    --cwd ~/output \\\n",
    "    --bfile burden/genotypes_21_22_plink.exome.bed \\\n",
    "    --genoFile burden/ukb23155_c2*_b0_v1.plink.exome.filtered.bed \\\n",
    "    --phenoFile burden/phenotype_burden_pca.txt \\\n",
    "    --keep_samples burden/unrelated_ind_burden.txt \\\n",
    "    --k 10 \\\n",
    "    --window 50 \\\n",
    "    --shift 10 \\\n",
    "    --r2 0.5 \\\n",
    "    --maf_filter 0.5 \\\n",
    "    --geno_filter 0.2 \\\n",
    "    --mind_filter 0.2 \\\n",
    "    --hwe_filter 0.0\\\n",
    "    --trait_name ethnicity \\\n",
    "    --numThreads 1 \\\n",
    "    --job_size 1 \\\n",
    "    --container_lmm /gpfs/gibbs/pi/dewan/data/UKBiobank/lmm.sif\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run PCA.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  king\n",
      "  filter\n",
      "  flashpca\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --bfile VAL (as path, required)\n",
      "                        Path to genotype array file\n",
      "  --genoFile  paths\n",
      "\n",
      "                        Plink binary files\n",
      "  --phenoFile VAL (as path, required)\n",
      "                        The phenotypic file\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --numThreads 1 (as int)\n",
      "                        Number of threads\n",
      "  --k VAL (as int, required)\n",
      "                        Number of Principal Components to output. Default is 10\n",
      "  --trait-name VAL (as str, required)\n",
      "                        Name of the trait in the phenoFile (format FID, IID,\n",
      "                        father, mother,trait )\n",
      "  --stand binom2\n",
      "                        How to standardize X before PCA\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.8'\n",
      "                        Merge data (FIXME:merge step) parameter: merge = True\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  king:                 Inference of relationships in the sample to remove\n",
      "                        closely related individuals\n",
      "    Workflow Options:\n",
      "      --kinship 0.0884 (as float)\n",
      "                        Filter based on kinship coefficient higher than a number\n",
      "                        (e.g first degree 0.25, second degree 0.125, third\n",
      "                        degree 0.0625)\n",
      "  filter_1:             Filter SNPs for PCA analysis and select individuals\n",
      "    Workflow Options:\n",
      "      --keep-samples VAL (as path, required)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "      --maf-filter 0.01 (as float)\n",
      "                        MAF filter to use\n",
      "      --geno-filter 0.01 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.02 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 5e-08 (as float)\n",
      "                        HWE filter\n",
      "  filter_2:             Merge all the .bed files into one bed file\n",
      "  filter_3:             LD prunning and remove related individuals (both ind of\n",
      "                        a pair)\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "                        Window size\n",
      "      --shift 10 (as int)\n",
      "                        Shift window every 10 snps\n",
      "      --r2 0.1 (as float)\n",
      "  flashpca_1:           Run PCA analysis using flashpca\n",
      "  flashpca_2:           Filter out outliers from bed file and filter related\n",
      "                        individuals to project them onto PCA\n",
      "  flashpca_3:           Re-do PCA without outliers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run PCA.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## PCA analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# Plink binary file\n",
    "parameter: genoFile = path\n",
    "# The phenotypic file\n",
    "parameter: phenoFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "\n",
    "# Name of the population column in the phenoFile (format FID, IID, father, mother, pop)\n",
    "parameter: pop_col = str\n",
    "parameter: pop = []\n",
    "# Software container option\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.8'\n",
    "suffix = '_'.join(pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run PCA analysis using flashpca \n",
    "[flashpca_1]\n",
    "# Number of Principal Components to output. Default is 10\n",
    "parameter: k = 10\n",
    "# How to standardize X before PCA\n",
    "parameter: stand = \"binom2\"\n",
    "input: genoFile, phenoFile\n",
    "output: f'{cwd}/{phenoFile:bn}.{(suffix+\".\") if suffix != \"\" else \"\"}pca.rds'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: container = container_lmm, expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    # Load required libraries\n",
    "    library(flashpcaR)\n",
    "  \n",
    "    ###\n",
    "    # FIXME: first extract data based on pop -- can we do that with flashpca?\n",
    "    ###\n",
    "  \n",
    "    f <- flashpca(${_input[0]:nr}, ndim=${k}, stand=\"${stand}\", do_loadings=TRUE, check_geno=TRUE)\n",
    "    # Use the projection file to generate pca plot\n",
    "    pca <- f$projection\n",
    "    pc_cov <- cov(f$projection[,-1])\n",
    "    pc_mean <- apply(f$projection[,-1], 2, mean)\n",
    "    colnames(pca) <- c(\"ID\",paste0(\"PC\", 1:${k}))\n",
    "    pca$IID <- sapply(strsplit(as.character(pca$ID),':'), \"[\", 1)\n",
    "    # Read fam file with phenotypes\n",
    "    pheno <- read.table(${_input[1]:r}, sep=\"\\t\", header=T )\n",
    "    pca <-merge(pheno, pca, by=\"IID\", all=FALSE) \n",
    "  \n",
    "    # save results\n",
    "    saveRDS(list(pca_model = f, pc_scores = pca, pc_mean=pc_mean, pc_cov = pc_cov, meta = \"${_input[1]:bn} ${suffix}\"), ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run PCA analysis using flashpca \n",
    "[plot_pca]\n",
    "parameter: pca_result = str\n",
    "input: pca_result\n",
    "output: f'{cwd}/{_input:bn}.pc.png',\n",
    "        f'{cwd}/{_input:bn}.scree.png'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: container = container_lmm, expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'   \n",
    "    library(dplyr)\n",
    "    library(ggplot2)\n",
    "    library(gridExtra)\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    f = dat$pca_model\n",
    "    pca_final = dat$pc_scores\n",
    "    k = length(dat$pc_mean)\n",
    "    ###\n",
    "    # Make the plots\n",
    "    ###\n",
    "    # Get the min and max values for x and y-axes \n",
    "    min_axis <- round(colMins(as.matrix(f$projection[sapply(f$projection, is.numeric)])),1)\n",
    "    max_axis <- round(colMaxs(as.matrix(f$projection[sapply(f$projection, is.numeric)])),1)\n",
    "    plot_pcs = function(pca_final, x, y, title=\"\") {\n",
    "      ggplot(pca_final, aes_string(x=x, y=y)) + geom_point(aes(color=${pop_col}, shape=${pop_col}), size=2) \n",
    "          + labs(title=title,x=x, y=y) \n",
    "          + scale_y_continuous(limits=c(min_axis, max_axis))  \n",
    "          + scale_x_continuous(limits=c(min_axis, max_axis)) \n",
    "          + theme_classic()\n",
    "    }\n",
    "    n_col = 3\n",
    "    n_row = 1\n",
    "    plots = lapply(1:(k-1), function(i) plot_pcs(pca, paste0(\"PC\",i), paste0(\"PC\",i+1), dat$meta))\n",
    "    png('${_output[0]}', width = 8, height = 4, unit='in', res=300)\n",
    "    do.call(gridExtra::grid.arrange, c(plots, list(ncol = n_col, nrow = n_row)))\n",
    "    dev.off()\n",
    "    # Create scree plot\n",
    "    PVE <- f$values\n",
    "    PVE <- round(PVE/sum(PVE), 2)\n",
    "    PVEplot <- qplot(c(1:k), PVE) + geom_line() + xlab(\"Principal Component\") + ylab(\"PVE\") + ggtitle(\"Scree Plot\") + ylim(0, 1) +scale_x_discrete(limits=factor(1:10))\n",
    "    PVE_cum <- cumsum(PVE)/sum(PVE)\n",
    "    cumPVEplot <- qplot(c(1:k), cumsum(PVE)) + geom_line() + xlab(\"Principal Component\") + ylab(\"PVE\") + ggtitle(\"Cumulative PVE Plot\") + ylim(0, 1) + scale_x_discrete(limits=factor(1:10))\n",
    "    png('${_output[1]}', width = 8, height = 4, unit='in', res=300)\n",
    "    grid.arrange(PVEplot, cumPVEplot, ncol = 2)\n",
    "    dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**FIXME: need an inner loop to do this per population** I leave it a parameter `per_pop`; in this case both global mean cov and per pop mean cov have to be saved from `flashpca` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Calculate Mahalanobis distance per population and report outliers\n",
    "[flash_pca_2, project_samples_2]\n",
    "# Set the probability to remove outliers eg 0.95 or 0.997\n",
    "parameter: prob = 0.95\n",
    "parameter: per_pop = False\n",
    "parameter: pca_result = path\n",
    "output: distance=f'{_input:n}.mahalanobis',\n",
    "        removed_outliers=f'{_input:n}.no_outliers',\n",
    "        analysis_summary=f'{_input:n}.analysis_summary.md',\n",
    "        qqplot_mahalanobis=f'{_input:n}.mahalanobis_qq.png',\n",
    "        hist_mahalanobis=f'{_input:n}.mahalanobis_hist.png'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container = container_lmm, expand = \"${ }\"\n",
    "    echo '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "      img {\n",
    "        height: 80%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "    ---    \n",
    "    ''' > ${_output[2]}\n",
    "    \n",
    "R: container = container_lmm, expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(ggplot2)\n",
    "    library(gridExtra)\n",
    "  \n",
    "    dat = readRDS(${_input:r})\n",
    "    pc <- dat$pc_scores %>%\n",
    "          select(\"IID\", \"${pop_col}\",starts_with(\"PC\"))\n",
    "    k = length(dat$pc_mean)\n",
    "    # Calculate mahalanobis distance\n",
    "    mu = t(t(pc[,c(-1,-2)]) - dat$pc_mean)\n",
    "    pc$mahal = rowSums(mu %*% solve(dat$pc_cov) * mu)\n",
    "    pc$p <- pchisq(pc$mahal, df=k, lower.tail=FALSE)\n",
    "    \n",
    "    # Set the cut-off to calculate outliers\n",
    "    out = capture.output(summary(pc$mahal))\n",
    "    write('# ${phenoFile:b} ${suffix} result summary\\n## Mahalanobis distance summary:\\n```', ${_output[2]:r}, append = T)\n",
    "    write.table(out, '${_output[2]}', sep=\"\\n\",append=TRUE)\n",
    "    write(\"```\", ${_output[2]:r}, append = T)\n",
    "    \n",
    "    manh_dis_sq_cutoff = quantile(pc$mahal,probs = ${prob}) # eg can use something like 6 sd from the mean chi-square double sided\n",
    "    write(paste(\"The cut-off for outlier removal is set to:\",manh_dis_sq_cutoff,\"and the number of individuals removed is:\", length(which(pc$mahal >= manh_dis_sq_cutoff)),\"\\n\"), ${_output[2]:r}, append = T)\n",
    "    \n",
    "    # Plot mahalanobis\n",
    "    png('${_output[3]}', width = 4, height = 4, unit='in', res=300)\n",
    "    qqplot(qchisq(ppoints(100), df=k), pc$mahal, main = expression(\"Q-Q plot of Mahalanobis\" * ~D^2 * \" vs. quantiles of\" * ~ chi[k]^2), xlab = expression(chi[2]^2 * \", probability points = 100\"), ylab = expression(D^2))\n",
    "    dev.off()\n",
    "    \n",
    "    png('${_output[4]}', width = 4, height = 4, unit='in', res=300)\n",
    "    ggplot(pc, aes(x=mahal)) + geom_histogram(aes(y = ..count..), binwidth = 0.5, colour = \"#1F3552\", fill = \"#4271AE\") + scale_x_continuous(name = \"Mahalanobis distance\") + theme_classic()\n",
    "    dev.off()\n",
    "    # Obtain the new sample\n",
    "    new_sample = pc[(pc$mahal <= manh_dis_sq_cutoff),1]\n",
    "    cat(\"The new sample size after outlier removal is:\",length(new_sample),\"\\n\", ${_output[2]:r}, append = T)\n",
    "    \n",
    "    sample_df <- pc %>%\n",
    "    mutate(FID = IID) %>%\n",
    "    select(FID, IID, ${pop_col},starts_with(\"PC\"), mahal, p)\n",
    "  \n",
    "    new_sample_no_out <- pc %>%\n",
    "    filter(IID %in% new_sample) %>%\n",
    "    mutate(FID=IID) %>%\n",
    "    select(FID,IID)\n",
    "  \n",
    "    # Save file with mahalanobis distance and IID for PCA recalculation\n",
    "    write.table(sample_df,${_output[0]:r}, sep=\"\\t\", quote=FALSE, row.names=FALSE, col.names=TRUE)\n",
    "    write.table(new_sample_no_out,${_output[1]:r}, sep=\"\\t\", quote=FALSE, row.names=FALSE, col.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Project related individuals back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Re-do PCA without outliers\n",
    "[project_samples_1]\n",
    "# Here genoFile is samples to be projected back\n",
    "parameter: pca_result = path\n",
    "input: genoFile, phenoFile, pca_result\n",
    "output: f'{_input[1]:n}.projected.rds'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    # Load required libraries\n",
    "    library(dplyr)\n",
    "    library(flashpcaR)\n",
    "    # Read the PLINK binary files\n",
    "    frel <- ${_input[0]:nr}\n",
    "    # Read loadings, center and scale from previous PCA\n",
    "    dat <- readRDS(${_input[2]:r})\n",
    "    f <- dat$pca_model\n",
    "    # Read the bim file to obtain reference alleles\n",
    "    bim <- read.table('${_input[0]:n}.bim')\n",
    "    ref <- as.character(bim[,5])\n",
    "    names(ref) <- bim[,2]\n",
    "    # Project related samples\n",
    "    fpro <- project(frel, loadings=f$loadings, orig_mean=f$center, orig_sd=f$scale, ref_allele=ref)\n",
    "    pca <- fpro$projection\n",
    "    k = length(dat$pc_mean)\n",
    "    colnames(pca) <- c(\"ID\",paste0(\"PC\", 1:k))\n",
    "    pca$IID <- sapply(strsplit(as.character(pca$ID),':'), \"[\", 1)\n",
    "    # Read fam file with phenotypes\n",
    "    pheno <- read.table(${_input[1]:r}, sep=\"\\t\", header=T )\n",
    "    pca <-merge(pheno, pca, by=\"IID\", all=FALSE) \n",
    "    dat$pc_scores = rbind(dat$pc_scores, pca)\n",
    "    \n",
    "    saveRDS(dat, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
