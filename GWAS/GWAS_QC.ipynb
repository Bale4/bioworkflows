{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "million-three",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# GWAS data QC workflow\n",
    "\n",
    "This workflow implements some prelimary data QC steps for PLINK input files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-premium",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook includes workflow for\n",
    "\n",
    "- Computer kinship matrix in sample and estimate related individuals\n",
    "- Genotype and sample QC: by MAF, missing data and HWE\n",
    "- LD pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-harvard",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Run this workflow\n",
    "\n",
    "Depending on the context of your problem, the workflow can be executed in two ways:\n",
    "\n",
    "1. Run `merge_plink` if necessary, to merge all samples first; then run `king` to perform kinship estimate and finally `qc` to do addition QC\n",
    "2. When you have a separate data-set for kinship estimate different from your genotype of interest, you can run `king`, followed by `qc`.\n",
    "\n",
    "In both cases, you should use the `*.related_id` output from `king` as the `--keep_samples` parameter input for `qc` step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-beach",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Minimal working example\n",
    "\n",
    "FIXME: first specify which of the 2 scenarios this example is for, then show how to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "changed-paragraph",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run GWAS_QC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  king\n",
      "  qc\n",
      "  merge_plink\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        the output directory for generated files\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --numThreads 20 (as int)\n",
      "                        Number of threads\n",
      "  --container-lmm 'statisticalgenetics/lmm:1.8'\n",
      "                        Software container option\n",
      "\n",
      "Sections\n",
      "  king:                 Inference of relationships in the sample to remove\n",
      "                        closely related individuals\n",
      "    Workflow Options:\n",
      "      --kinship 0.0625 (as float)\n",
      "                        Filter based on kinship coefficient higher than a number\n",
      "                        (e.g first degree 0.25, second degree 0.125, third\n",
      "                        degree 0.0625)\n",
      "      --genoFile VAL (as path, required)\n",
      "                        Plink binary file\n",
      "  qc_1:                 Filter SNPs and select individuals\n",
      "    Workflow Options:\n",
      "      --remove-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to remove (format FID, IID)\n",
      "      --keep-samples . (as path)\n",
      "                        The path to the file that contains the list of samples\n",
      "                        to keep (format FID, IID)\n",
      "      --maf-filter 0.01 (as float)\n",
      "                        MAF filter to use\n",
      "      --geno-filter 0.01 (as float)\n",
      "                        Maximum missingess per-variant\n",
      "      --mind-filter 0.02 (as float)\n",
      "                        Maximum missingness per-sample\n",
      "      --hwe-filter 5e-08 (as float)\n",
      "                        HWE filter\n",
      "      --genoFile  paths\n",
      "\n",
      "                        Plink binary files\n",
      "  qc_2:                 LD prunning and remove related individuals (both ind of\n",
      "                        a pair)\n",
      "    Workflow Options:\n",
      "      --window 50 (as int)\n",
      "                        Window size\n",
      "      --shift 10 (as int)\n",
      "                        Shift window every 10 snps\n",
      "      --r2 0.1 (as float)\n",
      "  qc_3:                 Merge all the .bed files into one bed file\n",
      "    Workflow Options:\n",
      "      --output-prefix ''\n",
      "  merge_plink:\n",
      "    Workflow Options:\n",
      "      --output-prefix VAL (as str, required)\n",
      "      --genoFile  paths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sos run GWAS_QC.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-arkansas",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Software container option\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.8'\n",
    "# use this function to edit memory string for PLINK input\n",
    "from sos.utils import expand_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-sheep",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Estimate kinship in the sample\n",
    "\n",
    "The output is a list of related individuals, as well as the kinship matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-episode",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Inference of relationships in the sample to remove closely related individuals\n",
    "[king]\n",
    "# Filter based on kinship coefficient higher than a number (e.g first degree 0.25, second degree 0.125, third degree 0.0625)\n",
    "parameter: kinship = 0.0625\n",
    "# Plink binary file\n",
    "parameter: genoFile = path\n",
    "input: genoFile\n",
    "output: f'{cwd}/{_input:bn}.kin0', related_samples = f'{cwd}/{_input:bn}.related_id'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout'\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      --make-king-table \\\n",
    "      --out ${_output[0]:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)}\n",
    "      \n",
    "R:  container=container_lmm, expand= \"${ }\", stderr = f'{_output[1]}.stderr', stdout = f'{_output[1]}.stdout'\n",
    "    library(dplyr)\n",
    "    kin0 <- read.table(${_output[0]:r}, header=F)\n",
    "    colnames(kin0) <- c(\"FID1\",\"ID1\",\"FID2\",\"ID2\",\"NSNP\",\"HETHET\",\"IBS0\",\"KINSHIP\")\n",
    "    rel <- kin0 %>%\n",
    "        filter(KINSHIP >= ${kinship})\n",
    "    cat(\"There are\", nrow(rel),\"related individuals using a kinship threshold of ${kinship}\\n\")\n",
    "    IID <- sort(unique(unlist(rel[, c(\"ID1\", \"ID2\")])))\n",
    "    df <- data.frame(IID)\n",
    "    df <- df %>%\n",
    "        mutate(FID = IID) %>%\n",
    "        select(FID, IID)\n",
    "    write.table(df,${_output[1]:r}, quote=FALSE, row.names=FALSE, col.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-sugar",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype and sample QC\n",
    "\n",
    "QC the genetic data based on MAF, sample and variant missigness and Hardy-Weinberg Equilibrium (HWE).\n",
    "\n",
    "In this step you may also provide a list of samples to keep, for example in the case when you would like to subset a sample based on their ancestries to perform independent analyses on each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-tokyo",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs and select individuals \n",
    "[qc_1 (basic QC filters)]\n",
    "# The path to the file that contains the list of samples to remove (format FID, IID)\n",
    "parameter: remove_samples = path('.')\n",
    "# The path to the file that contains the list of samples to keep (format FID, IID)\n",
    "parameter: keep_samples = path('.')\n",
    "# The path to the file that contains the list of variants to keep\n",
    "parameter: keep_variants = path('.')\n",
    "# MAF filter to use\n",
    "parameter: maf_filter = 0.01\n",
    "# Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.01\n",
    "# Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.02\n",
    "# HWE filter \n",
    "parameter: hwe_filter = 5e-08\n",
    "# Plink binary files\n",
    "parameter: genoFile = paths\n",
    "input: genoFile, group_by=1\n",
    "output: f'{cwd}/cache/{_input:bn}.filtered.bed'\n",
    "task: trunk_workers = 1, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    plink2 \\\n",
    "      --bfile ${_input:n} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} \\\n",
    "      ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} \\\n",
    "      ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} \\\n",
    "      ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      ${('--keep %s' % keep_samples) if keep_samples.is_file() else \"\"} \\\n",
    "      ${('--remove %s' % remove_samples) if remove_samples.is_file() else \"\"} \\\n",
    "      ${('--extract %s' % remove_samples) if keep_variants.is_file() else \"\"} \\\n",
    "      --make-bed \\\n",
    "      --out ${_output:n} \\\n",
    "      --threads ${numThreads} \\\n",
    "      --memory ${int(expand_size(mem) * 0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "terminal-jonathan",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning and remove related individuals (both ind of a pair)\n",
    "[qc_2 (LD pruning)]\n",
    "# Window size\n",
    "parameter: window = 50\n",
    "# Shift window every 10 snps\n",
    "parameter: shift = 10\n",
    "parameter: r2 = 0.1\n",
    "output: bed=f'{_input:n}.prune.bed', prune=f'{_input:n}.prune.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output[\"prune\"]:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}\n",
    "   \n",
    "    plink2 \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output['prune']} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output['bed']:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-church",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one bed file \n",
    "[qc_3 (merge all files)]\n",
    "parameter: output_prefix = \"\"\n",
    "output_prefix = f'{_input[0]:bn}.merged' if output_prefix == '' else output_prefix\n",
    "sos_run(\"merge_plink\", output_prefix=output_prefix, genoFile=_input['bed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-alloy",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[merge_plink]\n",
    "parameter: output_prefix = str\n",
    "parameter: genoFile = paths\n",
    "skip_if(len(genoFile) == 1)\n",
    "input: genoFile, group_by = 'all'\n",
    "output: f\"{_input[0]:d}/{output_prefix}.bed\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink2 \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory ${int(expand_size(mem) * 0.9)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
