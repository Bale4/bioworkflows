{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serial-reproduction",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# An example to submit a parallel SoS job on the cluster\n",
    "\n",
    "This notebook shows a toy example how to submit an SoS job on the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-breach",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For brevity I will simply write up a toy example here without explaining what each parameter is for. Please visit [SoS website](https://vatlab.github.io/sos-docs/) to learn more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-arthritis",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## A toy example script\n",
    "\n",
    "Here I write a workflow to create 10 text files, each file prints a line of text in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-replica",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: walltime = '1h'\n",
    "parameter: mem = '3G'\n",
    "parameter: ncore = 1\n",
    "parameter: job_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-cursor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[toy_example]\n",
    "parameter: n = 10\n",
    "n  = [x+1 for x in range(n)]\n",
    "input: for_each = 'n'\n",
    "output: f'File_{_n}.out'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = ncore, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = True, stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    echo {_n} > {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-composite",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Submit the workflow from login node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-coverage",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run the example on a cluster, eg `csg.yml` and on a queue `neurology` defined inside `csg.yml`:\n",
    "\n",
    "```\n",
    "sos run Job_Example.ipynb toy_example -c csg.yml -q neurology\n",
    "```\n",
    "\n",
    "You can then wait for this toy example to finish. In the mean time you can monitor its status, eg via `qstat -u <your username>` to check.\n",
    "\n",
    "Also defined in `csg.yml` there is another queue called `csg`:\n",
    "\n",
    "```\n",
    "sos run Job_Example.ipynb toy_example -c csg.yml -q csg -s force\n",
    "```\n",
    "\n",
    "Notice we use `-s force` so the existing output file will be ignored and new commands to generate the files will be submitted -- to demonstrate submitting to `csg` queue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-nashville",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Submit the workflow through a compute node\n",
    "\n",
    "It is encourage (in fact, **required**) that for long running jobs we submit the above command to a compute node that will distribute the 10 tasks from that node instead of from the login node. To implement this you have to create a text file, for example for CU Neurology cluster:\n",
    "\n",
    "```bash\n",
    "#!/bin/sh\n",
    "#$ -l h_rt=36:00:00\n",
    "#$ -l h_vmem=4G\n",
    "#$ -N job_submitter\n",
    "#$ -cwd\n",
    "#$ -S /bin/bash\n",
    "#$ -q csg.q\n",
    "\n",
    "export PATH=$HOME/miniconda3/bin:$PATH\n",
    "sos run Job_Example.ipynb toy_example -c csg.yml -q neurology -s force &> toy_example.log\n",
    "```\n",
    "\n",
    "As you can tell you requested 4GB memory and 36hrs to manage your pipeline execution. Please copy and save the contents about to a file called `toy_example.sh` and submit it via:\n",
    "\n",
    "```\n",
    "qsub toy_example.sh\n",
    "```\n",
    "\n",
    "You can check inside `toy_example.log`, for example use command:\n",
    "\n",
    "```\n",
    "cat toy_example.log\n",
    "```\n",
    "\n",
    "At the end of the job you should see exactly the same content as you have seen earlier on the screen when you submit jobs from login node.\n",
    "\n",
    "## Highlights on the job configuration template\n",
    "\n",
    "You can modify the job template file (`*.yml` file) as you see fit. A few places you might want to edit:\n",
    "\n",
    "1. `max_mem: 128G` is default to 128G. That means even if you specified more than this amount of memory, it is not going to request that much. Typically this default should reflect the maximum available memory from a specific queue of computing nodes. You can increase this value. For example all the nodes in `csg.q` at Columbia Neurology have at least 258G of memory.\n",
    "2. `max_running_jobs: 50` is to ensure the job you actually submit to the cluster at the same time, shown in `qstat`, is less than this value. We generally do not want to overflood the queue. But you can adjust this to be a bit higher especially when you notice the cluster is mostly idle and you want to exploit it some more.\n",
    "3. Add a new host, either based on existing host or from scratch. For example you can put in a big memory queue with a much larger `max_mem` and also changes to the job template as necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
