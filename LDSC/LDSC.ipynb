{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Stratified LD Score Regression (S-LDSC) Pipeline for Calculating Functional Enrichment and LD Scores**\n",
    "\n",
    "This notebook implements the pipepline for S-LDSC using python 2.7 and implementing the methods for ld score and enrichment calculations using the code defined in the [S-LDSC github repo](https://github.com/bulik/ldsc/wiki).\n",
    "\n",
    "Author: Anmol Singh, email: singh.anmol@columbia.edu, with input from Dr. Gao Wang"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This pipeline has been developed to integrate GWAS summary statistics data, annotation data, and LD reference panel data to compute functional enrichment for each of the epigenomic annotations that the user provides using the S-LDSC model. We will first start off with an introduction, instructions to set up, and the minimal working examples. Then the workflow code that can be run using SoS on any data will be at the end. \n",
    "\n",
    "## Introduction:\n",
    "\n",
    "\n",
    "To begin I will just give a brief introduction on LD Score Regression and what it is used for. For more in depth information on LD Score Regression please read the following three papers:\n",
    "\n",
    "1. \"LD Score regression distinguishes confounding from polygenicity in genome-wide association studies\" by Sullivan et al (2015)\n",
    "\n",
    "2. \"Partitioning heritability by functional annotation using genome-wide association summary statistics\" by Finucane et al (2015)\n",
    "\n",
    "3. \"Linkage disequilibrium–dependent architecture of human complex traits shows action of negative selection\" by Gazal et al (2017)\n",
    "\n",
    "As stated in Sullivan et al 2015, confounding factors and polygenic effects can cause inflated test statistics and other methods cannot distinguish between inflation from confounding bias and a true signal.\n",
    "\n",
    "Thus, LD Score Regression or LDSC is a technique that aims to identify the impact of confounding factors and polygenic effects using information from GWAS summary statistics.\n",
    "\n",
    "This approach involves using regression to mesaure the relationship between Linkage Disequilibrium (LD) scores and test statistics of SNPs from the GWAS summary statistics. \n",
    "\n",
    "Variants in LD with a causal variant show an elevation in test statistics in association analysis proportional to their LD (measured by r2) with the causal variant within a certain window size (could be 1 cM, 1kB, etc.). \n",
    "\n",
    "In contrast, inflation from confounders such as population stratification that occur purely from genetic drift will not correlate with LD.\n",
    "\n",
    "Thus, if we regress the χ2 statistics from GWAS against LD Score (LD Score regression), the intercept minus one is an estimator of the mean contribution of confounding bias to the inflation in the test statistics.\n",
    "\n",
    "Useful Formula to Help Explain LD Score Regression: \n",
    "\n",
    "\n",
    "\n",
    "Under a polygenic model, in which effect sizes for variants are drawn independently from distributions with variance proportional to  $1/(p(1-p))$ where p is the minor allele frequency (MAF), the expected $\\chi^2$ statistic of variant j is:\n",
    "\n",
    "\\begin{equation}\n",
    "E[\\chi^2|l_j] = Nh^2l_j/M + Na + 1 ...... (1)\n",
    "\\end{equation}\n",
    "where N is the sample size; M is the number of SNPs, such that h2/M is the average heritability explained per SNP; a measures the contribution of confounding biases, such as cryptic relatedness and population stratification; and $l_j = \\sum_k r^2_{jk}$ is the LD Score of variant j, which measures the amount of genetic variation tagged by j. \n",
    "\n",
    "(a full derivation of this equation is provided in the Supplementary Note of Sullivan et al (2015))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "From this we can see that, LD Score regression is useful in determining SNP-based heritability for a phenotype or trait.\n",
    "\n",
    "Heritability is the proportion of phenotypic variation (VP) that is due to variation in genetic values (VG) and thus can tell us how much of the difference in observed phenotypes in a sample is due to difference in genetics in the sample.\n",
    "\n",
    "But it can also be used to analyze partitioned heritability for a phenotype/trait split over categories. \n",
    "\n",
    "For Partitioned Heritability or Stratified LD Score Regression (S-LDSC) more power is added to our analysis by leveraging LD Score information as well as using SNPs that haven't reached Genome Wide Significance to partition heritability for a trait over categories which many other methods do not do. \n",
    "\n",
    "Furthermore, S-LDSC only requires that we have summary statistics for our SNPs and does not require genotype information like other methods such as REML do. \n",
    "\n",
    "S-LDSC relies on the fact that the χ2 association statistic for a given SNP includes the effects of all SNPs tagged by this SNP meaning that in a region of high LD in the genome the given SNP from the GWAS represents the effects of a group of SNPs in that region.\n",
    "\n",
    "Thus, for a polygenic trait, SNPs with a high LD score will have more significant χ2 statistics on average than SNPs with a low LD score.\n",
    "\n",
    "S-LDSC determines that a category of SNPs is enriched for heritability if SNPs with high LD to that category have more significant χ2 statistics than SNPs with low LD to that category.\n",
    "\n",
    "Here, enrichment of a category is defined as the proportion of SNP heritability in the category divided by the proportion of SNPs in that category.\n",
    "\n",
    "This formula is very useful to see how S-LDSC works:\n",
    "\n",
    "More precisely, under a polygenic model , the expected χ2 statistic of SNP j is\n",
    "\\begin{equation} \n",
    "E[\\chi^2_j] = N\\sum_CT_Cl(j,C) + Na + 1 ...... (2)\n",
    "\\end{equation} \n",
    "where N is sample size, C indexes categories, ℓ(j, C) is the LD score of SNP j with respect to category $l(j,C) = \\sum_{k\\epsilon C} r^2_{jk}$ , a is a term that measures the contribution of confounding biases, and if the categories are disjoint, $\\tau_C$ is the per-SNP heritability in category C; if the categories overlap, then the per-SNP heritability of SNP j is $\\sum_{C:j\\epsilon C} \\tau_C$.  Equation 2 allows us to estimate $\\tau_C$ via a (computationally simple) multiple regression of $\\chi^2$ against ℓ(j, C), for either a quantitative or case-control study. \n",
    "\n",
    "\n",
    "To see how these methods have been applied to real world data as well as a further discussion on methods and comparisons to other methods please read the three papers listed at the top of the tutorial. \n",
    "\n",
    "We will discuss how to conduct both types of LD Score regression in this tutorial using the ldsc program which can be found here: https://github.com/bulik/ldsc.\n",
    "\n",
    "\n",
    "\n",
    "## Installing LDSC with Conda:\n",
    "\n",
    "Make sure that you have installed python 2 and conda (if you want to install ldsc using conda). Conda can be installed using this link: https://store.continuum.io/cshop/anaconda/.\n",
    "\n",
    "### Step 1: Clone the Github Repository\n",
    "\n",
    "`git clone https://github.com/bulik/ldsc.git`\n",
    "\n",
    "`cd ldsc`\n",
    "\n",
    "### Step 2: Activate the Conda Environment\n",
    "\n",
    "`conda env create --file environment.yml`\n",
    "\n",
    "`source activate ldsc`\n",
    "\n",
    "### Step 3: Check to see if the main python scripts used for analysis are executable\n",
    "\n",
    "`./ldsc.py -h`\n",
    "\n",
    "`./munge_sumstats.py -h`\n",
    "\n",
    "Check to make sure that both `./ldsc.py -h` and `./munge_sumstats.py -h` output the list of all possible commands for both, otherwise there is something wrong with the installation.\n",
    "\n",
    "## Installing LDSC without Conda:\n",
    "\n",
    "### Step 1: Clone the Github Repository\n",
    "\n",
    "`git clone https://github.com/bulik/ldsc.git`\n",
    "\n",
    "`cd ldsc`\n",
    "\n",
    "### Step 2: Make the python scripts executeable\n",
    "\n",
    "`chmod +x ldsc.py`\n",
    "\n",
    "`chmod +x munge_sumstats.py`\n",
    "\n",
    "### Step 3: Check to see if the main python scripts used for analysis are executable\n",
    "\n",
    "`./ldsc.py -h`\n",
    "\n",
    "`./munge_sumstats.py -h`\n",
    "\n",
    "Since pybedtools is required for make_annot.py, if you need to make binary annotations and did not install through conda you must either install pybedtools on the cluster or use it through this docker image.\n",
    "\n",
    "### Step 4: Load Docker Image that has pybedtools\n",
    "\n",
    "`module load Singularity`\n",
    "\n",
    "`module load R`\n",
    "\n",
    "`singularity pull docker://quay.io/biocontainers/pybedtools-0.8.0-py27he860b03_1`\n",
    "\n",
    "Through this image you will now be able to use the make_annot.py script with no issues. \n",
    "\n",
    "## Example Analysis 1: Simple LD Score Regression\n",
    "\n",
    "This is a simple example of non-partitioned LD Score Regression.\n",
    "\n",
    "You can find the plink files needed for this tutorial here: https://data.broadinstitute.org/alkesgroup/LDSCORE/1000G_Phase3_plinkfiles.tgz. This file contains the bim/bam/fam files for 489 subjects for all 1000 Genome Phase 3 SNPs which will be used as the reference panel for our analysis.\n",
    "\n",
    "Now, after downloading the data we can take a look at a simple example calculating the LD scores for 1000 Genome Phase 3 variants on chromosome 22. To conduct the regression we must do this for every chromosome but the commands are the same so I will just show it for one. A great way that I have found to loop over all the chromosomes in parallel is to use xargs:\n",
    "\n",
    "seq 1 22| xargs -n 1 -I j -P 4 python ldsc.py --bfile 1000G.EUR.QC.j --l2 --ld-wind-cm 1 --out tutorial.j &\n",
    "\n",
    "This xargs command will loop over the command passed to it using the iterative variable j (marked with the -I flag). The -n 1 flag indicates that there is one iterative variable and the -P 4 flag indicates that 4 of the iterative commands will be submitted at a time (e.g. chr1,chr2,chr3,chr4 will be submitted in a batch and then after that is done the next 4 will start).\n",
    "\n",
    "For the command flags: --bfile indicates that the file is a plink bed/bim/fam file with that prefix, --l2 indicates you want to calculate LD Scores, --ld-wind-cm indicates that you want to calculate LD Scores using a 1 cM window, and --out indicates the prefix you want to use for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "* LD Score Regression (LDSC)\n",
      "* Version 1.0.1\n",
      "* (C) 2014-2019 Brendan Bulik-Sullivan and Hilary Finucane\n",
      "* Broad Institute of MIT and Harvard / MIT Department of Mathematics\n",
      "* GNU General Public License v3\n",
      "*********************************************************************\n",
      "Call: \n",
      "./ldsc.py \\\n",
      "--ld-wind-cm 1.0 \\\n",
      "--out tutorial.7 \\\n",
      "--bfile /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_Phase3_plink/1000G.EUR.QC.7 \\\n",
      "--l2  \n",
      "\n",
      "Beginning analysis at Thu Jan  6 20:53:02 2022\n",
      "Read list of 589569 SNPs from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_Phase3_plink/1000G.EUR.QC.7.bim\n",
      "Read list of 489 individuals from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_Phase3_plink/1000G.EUR.QC.7.fam\n",
      "Reading genotypes from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_Phase3_plink/1000G.EUR.QC.7.bed\n",
      "Estimating LD Score.\n",
      "Writing LD Scores for 589569 SNPs to tutorial.7.l2.ldscore.gz\n",
      "\n",
      "Summary of LD Scores in tutorial.7.l2.ldscore.gz\n",
      "         MAF         L2\n",
      "mean  0.1498   118.3970\n",
      "std   0.1496   146.2625\n",
      "min   0.0051   -12.0144\n",
      "25%   0.0194    33.6981\n",
      "50%   0.0879    77.0755\n",
      "75%   0.2587   150.3558\n",
      "max   0.5000  1236.5470\n",
      "\n",
      "MAF/LD Score Correlation Matrix\n",
      "        MAF      L2\n",
      "MAF  1.0000  0.3169\n",
      "L2   0.3169  1.0000\n",
      "Analysis finished at Thu Jan  6 21:05:04 2022\n",
      "Total time elapsed: 12.0m:1.73s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python2 ldsc.py \\\n",
    "    --bfile 1000G.EUR.QC.7\\\n",
    "    --l2\\\n",
    "    --ld-wind-cm 1\\\n",
    "    --out tutorial.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "The output of this command shows a summary of the LD Scores and the MAF/LD Score correlation matrix which is useful for conducting QC on the analysis. The MAF and LD Scores should be positively correlated.\n",
    "\n",
    "The command also creates a file with the LD Scores that are gzipped. An example output is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHR</th>\n",
       "      <th>SNP</th>\n",
       "      <th>BP</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>rs587616822</td>\n",
       "      <td>16050840</td>\n",
       "      <td>3.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>rs62224609</td>\n",
       "      <td>16051249</td>\n",
       "      <td>10.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>rs587646183</td>\n",
       "      <td>16052463</td>\n",
       "      <td>1.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>rs139918843</td>\n",
       "      <td>16052684</td>\n",
       "      <td>4.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>rs587743102</td>\n",
       "      <td>16052837</td>\n",
       "      <td>2.057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHR          SNP        BP      L2\n",
       "0   22  rs587616822  16050840   3.795\n",
       "1   22   rs62224609  16051249  10.431\n",
       "2   22  rs587646183  16052463   1.361\n",
       "3   22  rs139918843  16052684   4.825\n",
       "4   22  rs587743102  16052837   2.057"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"tutorial.22.l2.ldscore.gz\",sep=\"\\t\") \n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "After calculating LD Scores for each chromosome, it is time to set up the summary statistic file for the phenotype you are trying to analyze. The summary statistic file we will use is for BMI and it can be downloaded here: http://www.broadinstitute.org/collaboration/giant/index.php/GIANT_consortium_data_files. For the tutorial you also need the list of hapmap snps to restrict the summary statistic file to the recommended HapMap Phase 3 SNPs that will be used in the regression. The authors recommend restricting the analysis to HapMap Phase 3 SNPs because most GWAS summary statistics do not have information about imputation quality, thus using HapMap SNPs insures that you are using well-imputed and common variants for the analysis. This file can be downloaded here: https://storage.googleapis.com/broad-alkesgroup-public/LDSCORE/w_hm3.snplist.bz2. The summary statistic file should have the following columns with the following names for the analysis to work:\n",
    "\n",
    "SNP -- SNP identifier (e.g., rs number)\n",
    "\n",
    "N -- sample size (which may vary from SNP to SNP).\n",
    "\n",
    "P -- p-value.\n",
    "\n",
    "A1 -- first allele (effect allele)\n",
    "\n",
    "A2-- second allele (other allele)\n",
    "\n",
    "Signed Summary Statistic (Can be Z, BETA, or Odds Ratio(label as OR)), is optional if A1 is the risk increasing allele as you can put the flag --a1-inc in the command and ldsc will calculate the Z score for the SNPs for you\n",
    "\n",
    "Once you have set up the summary statistic file with these column headers you can reformat it for the analysis using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "* LD Score Regression (LDSC)\n",
      "* Version 1.0.1\n",
      "* (C) 2014-2019 Brendan Bulik-Sullivan and Hilary Finucane\n",
      "* Broad Institute of MIT and Harvard / MIT Department of Mathematics\n",
      "* GNU General Public License v3\n",
      "*********************************************************************\n",
      "Call: \n",
      "./munge_sumstats.py \\\n",
      "--out BMI \\\n",
      "--merge-alleles w_hm3.snplist/w_hm3.snplist \\\n",
      "--a1-inc  \\\n",
      "--sumstats GIANT_BMI_Speliotes2010_publicrelease_HapMapCeuFreq.txt \n",
      "\n",
      "Interpreting column names as follows:\n",
      "Allele2:\tAllele 2, interpreted as non-ref allele for signed sumstat.\n",
      "MarkerName:\tVariant ID (e.g., rs number)\n",
      "Allele1:\tAllele 1, interpreted as ref allele for signed sumstat.\n",
      "p:\tp-Value\n",
      "N:\tSample size\n",
      "\n",
      "Reading list of SNPs for allele merge from w_hm3.snplist/w_hm3.snplist\n",
      "Read 1217311 SNPs for allele merge.\n",
      "Reading sumstats from GIANT_BMI_Speliotes2010_publicrelease_HapMapCeuFreq.txt into memory 5000000 SNPs at a time.\n",
      "Read 2471516 SNPs from --sumstats file.\n",
      "Removed 1400863 SNPs not in --merge-alleles.\n",
      "Removed 0 SNPs with missing values.\n",
      "Removed 0 SNPs with INFO <= 0.9.\n",
      "Removed 0 SNPs with MAF <= 0.01.\n",
      "Removed 0 SNPs with out-of-bounds p-values.\n",
      "Removed 6 variants that were not SNPs or were strand-ambiguous.\n",
      "1070647 SNPs remain.\n",
      "Removed 0 SNPs with duplicated rs numbers (1070647 SNPs remain).\n",
      "Removed 29808 SNPs with N < 82575.3333333 (1040839 SNPs remain).\n",
      "Removed 36 SNPs whose alleles did not match --merge-alleles (1040803 SNPs remain).\n",
      "Writing summary statistics for 1217311 SNPs (1040803 with nonmissing beta) to BMI.sumstats.gz.\n",
      "\n",
      "Metadata:\n",
      "Mean chi^2 = 1.112\n",
      "Lambda GC = 1.038\n",
      "Max chi^2 = 277.2\n",
      "337 Genome-wide significant SNPs (some may have been removed by filtering).\n",
      "\n",
      "Conversion finished at Sat Jun 26 15:53:04 2021\n",
      "Total time elapsed: 51.85s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python2 munge_sumstats.py --sumstats GIANT_BMI_Speliotes2010_publicrelease_HapMapCeuFreq.txt\\\n",
    "--merge-alleles w_hm3.snplist\\\n",
    "--out BMI\\\n",
    " --a1-inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This will return a file called BMI.sumstats.gz which is a gzipped file that will be used as the summary statistic file in our analysis. It contains a row for each variant as well as the Allele Information and the Z score calculated by the munge_sumstats.py program.\n",
    "\n",
    "Now we can conduct the Simple LD Score Regression using the following command listed below. We will have to download the weights for all hapmap snps excluding the HLA gene region for this analysis, which can be found here: https://storage.googleapis.com/broad-alkesgroup-public/LDSCORE/weights_hm3_no_hla.tgz. The authors excluded the HLA gene region due to the unusual genetic architecture and LD pattern in this region.\n",
    "\n",
    "For the command flags: --h2 indicates that you want to conduct LD Score regression using the gzipped summary statistic file we made in the last part, --ref-ld-chr indicates the reference genome LD Scores which were calculated in the section above, --w-ld-chr indicates the files that contains weights for the regression SNPs that the program can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "* LD Score Regression (LDSC)\n",
      "* Version 1.0.1\n",
      "* (C) 2014-2019 Brendan Bulik-Sullivan and Hilary Finucane\n",
      "* Broad Institute of MIT and Harvard / MIT Department of Mathematics\n",
      "* GNU General Public License v3\n",
      "*********************************************************************\n",
      "Call: \n",
      "./ldsc.py \\\n",
      "--h2 BMI.sumstats.gz \\\n",
      "--ref-ld-chr tutorial. \\\n",
      "--out tutorial \\\n",
      "--frqfile-chr 1000G_frq/1000G.mac5eur. \\\n",
      "--w-ld-chr weights_hm3_no_hla/weights. \n",
      "\n",
      "Beginning analysis at Fri Jan  7 01:15:50 2022\n",
      "The frequency file is unnecessary and is being ignored.\n",
      "Reading summary statistics from BMI.sumstats.gz ...\n",
      "Read summary statistics for 1040803 SNPs.\n",
      "Reading reference panel LD Score from tutorial.[1-22] ... (ldscore_fromlist)\n",
      "Read reference panel LD Scores for 9997231 SNPs.\n",
      "Removing partitioned LD Scores with zero variance.\n",
      "Reading regression weight LD Score from weights_hm3_no_hla/weights.[1-22] ... (ldscore_fromlist)\n",
      "Read regression weight LD Scores for 1242190 SNPs.\n",
      "After merging with reference panel LD, 1029225 SNPs remain.\n",
      "After merging with regression SNP LD, 938794 SNPs remain.\n",
      "Using two-step estimator with cutoff at 30.\n",
      "Total Observed scale h2: 0.1111 (0.0064)\n",
      "Lambda GC: 1.0375\n",
      "Mean Chi^2: 1.1142\n",
      "Intercept: 0.8146 (0.0091)\n",
      "Ratio < 0 (usually indicates GC correction).\n",
      "Analysis finished at Fri Jan  7 01:16:52 2022\n",
      "Total time elapsed: 1.0m:1.19s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python2 ldsc.py \\\n",
    "--h2 BMI.sumstats.gz \\\n",
    "--ref-ld-chr tutorial. \\\n",
    "--w-ld-chr ./weights_hm3_no_hla/weights. \\\n",
    "--out tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Now we have estimated the proportion of heritability that is attributed to the BMI phenotype which is shown in the output above. Note that this value should be between 0 and 1 but can be a bit below 0 due to standard errors during calculation.\n",
    "\n",
    "Heritability is formally defined as the proportion of phenotypic variation (VP) that is due to variation in genetic values (VG).\n",
    "\n",
    "Thus, in this case the proportion of phenotypic variance for BMI that is due to genetic factors is relatively low.\n",
    "\n",
    "Lambda GC is the genomic inflation factor which tells us how much systematic bias is present in our data, it is calculated in this case by median(chi^2)/0.4549. The value should be close to 1.\n",
    "\n",
    "Mean chi^2 is the mean chi-square statistic and should be above 1.02.\n",
    "\n",
    "Intercept is the LD Score regression intercept. The intercept should be close to 1, unless the data have been corrected for GC bias or Genomic Control Bias which controls for bias from population stratification, in which case it will often be lower. Note that the intercept in our case is below 1 because the summary statistics file we used has been corrected for GC bias.\n",
    "\n",
    "Ratio is (intercept-1)/(mean(chi^2)-1), which measures the proportion of the inflation in the mean chi^2 that the LD Score regression intercept ascribes to causes other than polygenic heritability. The value of ratio should be close to zero, though in practice values of 10-20% are not uncommon, probably due to sample/reference LD Score mismatch or model misspecification (e.g., low LD variants have slightly higher h^2 per SNP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Example Analysis 2: Partitioned LD Score Regression\n",
    "\n",
    "We first make the annotation file with respect to a specific annotation bed file using the make_annot.py script that comes with the ldsc program. For the purposes of this tutorial we will use a Histone Mark annotation from Adipose Tissue, Adipose_Tissue.H3K27ac. I have provided the bed file for this annotation on a google drive folder (https://drive.google.com/drive/folders/1HdG-QsCl6fAspSxGsuoOCapwfnXCyfnU?usp=sharing) so you can download it to run the commands below. The command to make the annotation file for this annotation for one chromosome of the 1000 Genome Phase 3 variants (the reference data) for the tutorial is listed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python2 make_annot.py \\\n",
    "\t\t--bed-file Adipose_Tissue.H3K27ac.bed \\\n",
    "\t\t--bimfile 1000G.EUR.QC.22.bim \\\n",
    "\t\t--annot-file Adipose_Tissue.H3K27ac.annot.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ANNOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ANNOT\n",
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"Adipose_Tissue.H3K27ac.22.annot.gz\",sep=\"\\t\") \n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This command will output a file with 0/1 for each variant in the bim file as shown above which corresponds to whether this specific variant is within the regions described in the annotation file.\n",
    "\n",
    "After the annotation file is made we can use it to calculate the LD Scores for this annotation. This will be done using the command below for chromosome 22, remember you have to repeat the same command for every chromsome in the reference panel. In this case the program recommends that you only print LD Scores for HapMap Phase 3 SNPs. This can be achieved by using the hapmap snplist file which can be found here: https://storage.googleapis.com/broad-alkesgroup-public/LDSCORE/w_hm3.snplist.bz2. **You must get rid of the A1 and A2 columns in this file and keep only the SNP column before using the command below**\n",
    "\n",
    "For this command the difference is that we add the --annot flag which indicates the annotation file we are using and the --thin-annot flag which indicates that the annotation file does not contain any information about the SNPs (rs number, CHR, and BP) and only contains the binary scores for the annotation.\n",
    "\n",
    "Make sure your annotation files have the same prefix as your LD Score files that you will create as ldsc will not be able to read the annotation files if they have a different prefix when you try to conduct the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "* LD Score Regression (LDSC)\n",
      "* Version 1.0.1\n",
      "* (C) 2014-2019 Brendan Bulik-Sullivan and Hilary Finucane\n",
      "* Broad Institute of MIT and Harvard / MIT Department of Mathematics\n",
      "* GNU General Public License v3\n",
      "*********************************************************************\n",
      "Call: \n",
      "./ldsc.py \\\n",
      "--print-snps /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/hapmap_snplist.txt \\\n",
      "--ld-wind-cm 1.0 \\\n",
      "--out Adipose_Tissue.H3K27ac.22 \\\n",
      "--bfile /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_filtered/1000G.22.final \\\n",
      "--thin-annot  \\\n",
      "--annot Adipose_Tissue.H3K27ac.22.annot.gz \\\n",
      "--l2  \n",
      "\n",
      "Beginning analysis at Sun Jun 27 07:38:17 2021\n",
      "Read list of 113121 SNPs from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_filtered/1000G.22.final.bim\n",
      "Read 1 annotations for 113121 SNPs from Adipose_Tissue.H3K27ac.22.annot.gz\n",
      "Read list of 489 individuals from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_filtered/1000G.22.final.fam\n",
      "Reading genotypes from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/1000G_EUR_filtered/1000G.22.final.bed\n",
      "Estimating LD Score.\n",
      "Reading list of 1217311 SNPs for which to print LD Scores from /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/hapmap_snplist.txt\n",
      "After merging with --print-snps, LD Scores for 17051 SNPs will be printed.\n",
      "Writing LD Scores for 17051 SNPs to Adipose_Tissue.H3K27ac.22.l2.ldscore.gz\n",
      "\n",
      "Summary of LD Scores in Adipose_Tissue.H3K27ac.22.l2.ldscore.gz\n",
      "         MAF        L2\n",
      "mean  0.2331   60.8339\n",
      "std   0.1405   57.0112\n",
      "min   0.0051    0.7912\n",
      "25%   0.1084   24.9624\n",
      "50%   0.2249   43.2079\n",
      "75%   0.3507   77.1605\n",
      "max   0.5000  448.2311\n",
      "\n",
      "MAF/LD Score Correlation Matrix\n",
      "        MAF      L2\n",
      "MAF  1.0000  0.1245\n",
      "L2   0.1245  1.0000\n",
      "\n",
      "Annotation Correlation Matrix\n",
      "       ANNOT\n",
      "ANNOT    1.0\n",
      "\n",
      "Annotation Matrix Column Sums\n",
      "ANNOT    82990\n",
      "\n",
      "Summary of Annotation Matrix Row Sums\n",
      "count    113121.0000\n",
      "mean          0.7336\n",
      "std           0.4421\n",
      "min           0.0000\n",
      "25%           0.0000\n",
      "50%           1.0000\n",
      "75%           1.0000\n",
      "max           1.0000\n",
      "Analysis finished at Sun Jun 27 07:39:25 2021\n",
      "Total time elapsed: 1.0m:8.93s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python2 ldsc.py \\\n",
    "    --bfile 1000G.EUR.QC.22\\\n",
    "    --l2\\\n",
    "    --ld-wind-cm 1 --annot Adipose_Tissue.H3K27ac.22.annot.gz --thin-annot\\\n",
    "    --out Adipose_Tissue.H3K27ac.22\\\n",
    "    --print-snps w_hm3.snplist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This command outputs the same gzipped LD score file as the simple case but instead of just an LD Score column, it will have one LD Score column for each annotation that you are calculating LD Scores for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHR</th>\n",
       "      <th>SNP</th>\n",
       "      <th>BP</th>\n",
       "      <th>L2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>rs7287144</td>\n",
       "      <td>16886873</td>\n",
       "      <td>6.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>rs5748662</td>\n",
       "      <td>16892858</td>\n",
       "      <td>5.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>rs4010554</td>\n",
       "      <td>16894264</td>\n",
       "      <td>7.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>rs4010558</td>\n",
       "      <td>16896762</td>\n",
       "      <td>7.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>rs2379981</td>\n",
       "      <td>17030792</td>\n",
       "      <td>19.616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CHR        SNP        BP      L2\n",
       "0   22  rs7287144  16886873   6.932\n",
       "1   22  rs5748662  16892858   5.780\n",
       "2   22  rs4010554  16894264   7.341\n",
       "3   22  rs4010558  16896762   7.412\n",
       "4   22  rs2379981  17030792  19.616"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"Adipose_Tissue.H3K27ac.22.l2.ldscore.gz\",sep=\"\\t\") \n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Now that we have calculated the LD Scores for each chromosome for our annotation, we can use these LD Scores to conduct the Partitioned LD Score Regression for our annotation. In this case we have to make sure that our annotation files are in the same folder and have the same prefix name as our LD Score files. Now we can conduct the Regression for our annotation:\n",
    "\n",
    "The new flag --frqfile-chr is used to add the MAF frequencies for the reference genome SNPs since we will only be using SNPs with a MAF>0.05 to conduct the analysis. The baseline annotation is an annotation consisiting of all 1's and is the intercept of the LD Score Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "* LD Score Regression (LDSC)\n",
      "* Version 1.0.1\n",
      "* (C) 2014-2019 Brendan Bulik-Sullivan and Hilary Finucane\n",
      "* Broad Institute of MIT and Harvard / MIT Department of Mathematics\n",
      "* GNU General Public License v3\n",
      "*********************************************************************\n",
      "Call: \n",
      "./ldsc.py \\\n",
      "--h2 BMI.sumstats.gz \\\n",
      "--ref-ld-chr baselineLD/base.,Adipose_Tissue.H3K27ac. \\\n",
      "--out Adipose_Tissue.H3K27ac \\\n",
      "--overlap-annot  \\\n",
      "--frqfile-chr 1000G_frq/1000G.mac5eur. \\\n",
      "--w-ld-chr weights_hm3_no_hla/weights. \n",
      "\n",
      "Beginning analysis at Thu Jan  6 00:56:01 2022\n",
      "Reading summary statistics from BMI.sumstats.gz ...\n",
      "Read summary statistics for 1040803 SNPs.\n",
      "Reading reference panel LD Score from baselineLD/base.,Adipose_Tissue.H3K27ac.[1-22] ... (ldscore_fromlist)\n",
      "Read reference panel LD Scores for 1168549 SNPs.\n",
      "Removing partitioned LD Scores with zero variance.\n",
      "Reading regression weight LD Score from weights_hm3_no_hla/weights.[1-22] ... (ldscore_fromlist)\n",
      "Read regression weight LD Scores for 1242190 SNPs.\n",
      "After merging with reference panel LD, 1013453 SNPs remain.\n",
      "After merging with regression SNP LD, 924379 SNPs remain.\n",
      "Removed 15 SNPs with chi^2 > 123.912 (924364 SNPs remain)\n",
      "Total Observed scale h2: 0.122 (0.0074)\n",
      "Categories: baseL2_0 L2_1\n",
      "Lambda GC: 1.0375\n",
      "Mean Chi^2: 1.109\n",
      "Intercept: 0.7934 (0.0109)\n",
      "Ratio < 0 (usually indicates GC correction).\n",
      "Reading annot matrix from baselineLD/base.,Adipose_Tissue.H3K27ac.[1-22] ... (annot)\n",
      "Results printed to Adipose_Tissue.H3K27ac.results\n",
      "Analysis finished at Thu Jan  6 00:56:58 2022\n",
      "Total time elapsed: 57.53s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python2 ldsc.py \\\n",
    "    --h2 BMI.sumstats.gz\\\n",
    "    --ref-ld-chr base.,Adipose_Tissue.H3K27ac.\\ \n",
    "    --w-ld-chr weights_hm3_no_hla/weights.\\\n",
    "    --overlap-annot\\\n",
    "    --frqfile-chr 1000G_frq/1000G.mac5eur.\\\n",
    "    --out Adipose_Tissue.H3K27ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Here the comma indicates that we are concatinating the baseline model with the new annotation.\n",
    "\n",
    "The results our outputted in a .results file which shows the proportion of heritability and enrichment attributable to each category for the trait you are studying, in this case BMI.\n",
    "\n",
    "The results file for this analysis looks like this, where L2_1 represents our Adipose Tissue Annotation and baseL2_0 describes the baseline annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "kernel": "Python 3 (ipykernel)",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Prop._SNPs</th>\n",
       "      <th>Prop._h2</th>\n",
       "      <th>Prop._h2_std_error</th>\n",
       "      <th>Enrichment</th>\n",
       "      <th>Enrichment_std_error</th>\n",
       "      <th>Enrichment_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseL2_0</td>\n",
       "      <td>1.028145</td>\n",
       "      <td>0.978165</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.951388</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>1.793667e-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L2_1</td>\n",
       "      <td>0.600255</td>\n",
       "      <td>0.993930</td>\n",
       "      <td>0.063355</td>\n",
       "      <td>1.655848</td>\n",
       "      <td>0.105547</td>\n",
       "      <td>2.752202e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category  Prop._SNPs  Prop._h2  Prop._h2_std_error  Enrichment  \\\n",
       "0  baseL2_0    1.028145  0.978165            0.000830    0.951388   \n",
       "1      L2_1    0.600255  0.993930            0.063355    1.655848   \n",
       "\n",
       "   Enrichment_std_error  Enrichment_p  \n",
       "0              0.000807  1.793667e-37  \n",
       "1              0.105547  2.752202e-08  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(\"Adipose_Tissue.H3K27ac.results\",sep=\"\\t\") \n",
    "\n",
    "\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SoS Workflow:\n",
    "\n",
    "This part of the notebook will allow you to run LDSC commands with your own data using this pipeline.\n",
    "\n",
    "## Command Interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LDSC.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  make_annot\n",
      "  munge_sumstats_no_sign\n",
      "  munge_sumstats_sign\n",
      "  calc_ld_score\n",
      "  calc_enrichment\n",
      "\n",
      "Sections\n",
      "  make_annot:\n",
      "    Workflow Options:\n",
      "      --bed VAL (as str, required)\n",
      "                        path to bed file\n",
      "      --bim VAL (as str, required)\n",
      "                        path to bim file\n",
      "      --annot VAL (as str, required)\n",
      "                        name of output annotation file\n",
      "  munge_sumstats_no_sign: This option is for when the summary statistic file\n",
      "                        does not contain a signed summary statistic (Z or Beta).\n",
      "                        In this case,the program will calculate Z for you based\n",
      "                        on A1 being the risk allele\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output VAL (as str, required)\n",
      "                        path to output file\n",
      "  munge_sumstats_sign:  This option is for when the summary statistic file does\n",
      "                        contain a signed summary statistic (Z or Beta)\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output VAL (as str, required)\n",
      "                        path to output file\n",
      "  calc_ld_score:        Calculate LD Scores **Make sure to delete SNP,CHR, and\n",
      "                        BP columns from annotation files if they are present\n",
      "                        otherwise this code will not work. Before deleting, if\n",
      "                        these columns are present, make sure that the annotation\n",
      "                        file is sorted.**\n",
      "    Workflow Options:\n",
      "      --bim VAL (as str, required)\n",
      "                        Path to bim file\n",
      "      --annot-file VAL (as str, required)\n",
      "                        Path to annotation File. Make sure to remove the SNP,\n",
      "                        CHR, and BP columns from the annotation file if present\n",
      "                        before running.\n",
      "      --output VAL (as str, required)\n",
      "                        name of output file\n",
      "      --snplist 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, remove the A1 and A2 columns\n",
      "                        for the Calculate LD Scores program\n",
      "  calc_enrichment:\n",
      "    Workflow Options:\n",
      "      --sumstats VAL (as str, required)\n",
      "                        Path to Summary statistics File\n",
      "      --ref-ld VAL (as str, required)\n",
      "                        Path to Reference LD Scores Files (Base Annotation +\n",
      "                        Annotation you want to analyze, format like minimal\n",
      "                        working example)\n",
      "      --w-ld VAL (as str, required)\n",
      "                        Path to LD Weight Files (Format like minimal working\n",
      "                        example)\n",
      "      --frq-file VAL (as str, required)\n",
      "                        path to frequency files (Format like minimal working\n",
      "                        example)\n",
      "      --output VAL (as str, required)\n",
      "                        Output name\n"
     ]
    }
   ],
   "source": [
    "!sos run LDSC.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Make Annotation File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[make_annot]\n",
    "\n",
    "# Make Annotated Bed File\n",
    "\n",
    "# path to bed file\n",
    "parameter: bed = str \n",
    "#path to bim file\n",
    "parameter: bim = str\n",
    "#name of output annotation file\n",
    "parameter: annot = str\n",
    "bash: \n",
    "    python2 make_annot.py --bed-file {bed} --bimfile {bim} --annot-file {annot}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Munge Summary Statistics (Option 1: No Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#This option is for when the summary statistic file does not contain a signed summary statistic (Z or Beta). \n",
    "#In this case,the program will calculate Z for you based on A1 being the risk allele\n",
    "[munge_sumstats_no_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: \n",
    "    python2 munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output} --a1-inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Munge Summary Statistics (Option 2: No Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This option is for when the summary statistic file does contain a signed summary statistic (Z or Beta)\n",
    "[munge_sumstats_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: \n",
    "    python2 munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate LD Scores:\n",
    "\n",
    "**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate LD Scores\n",
    "#**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**\n",
    "[calc_ld_score]\n",
    "\n",
    "#Path to bim file\n",
    "parameter: bim = str\n",
    "#Path to annotation File. Make sure to remove the SNP, CHR, and BP columns from the annotation file if present before running.\n",
    "parameter: annot_file = str\n",
    "#name of output file\n",
    "parameter: output = str\n",
    "#path to Hapmap3 SNPs file, remove the A1 and A2 columns for the Calculate LD Scores program \n",
    "parameter: snplist = \"w_hm3.snplist\"\n",
    "\n",
    "bash: \n",
    "    python2 ldsc.py --bfile {bim} --l2 --ld-wind-cm 1 --annot {annot_file} --thin-annot --out {output} --print-snps {snplist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate Functional Enrichment using Annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate Enrichment Scores for Functional Annotations\n",
    "\n",
    "[calc_enrichment]\n",
    "\n",
    "#Path to Summary statistics File\n",
    "parameter: sumstats = str\n",
    "#Path to Reference LD Scores Files (Base Annotation + Annotation you want to analyze, format like minimal working example)\n",
    "parameter: ref_ld = str\n",
    "#Path to LD Weight Files (Format like minimal working example)\n",
    "parameter: w_ld = str\n",
    "#path to frequency files (Format like minimal working example)\n",
    "parameter: frq_file = str\n",
    "#Output name\n",
    "parameter: output = str\n",
    "\n",
    "bash:\n",
    "    python2 ldsc.py --h2 {sumstats} --ref-ld-chr {ref_ld} --w-ld-chr {w_ld} --overlap-annot --frqfile-chr {frq_file} --out {output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Python 3 (ipykernel)",
     "python3",
     "python3",
     "",
     {
      "name": "ipython",
      "version": 3
     }
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
