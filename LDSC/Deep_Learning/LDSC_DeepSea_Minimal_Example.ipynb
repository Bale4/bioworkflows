{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## SoS Workflow:\n",
    "\n",
    "This is the options and the SoS code to run the LDSC pipeline using your own data. \n",
    "\n",
    "## Command Interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No help information is available for script run: Failed to locate LDSC_DeepSea_Code.ipynb.sos\r\n"
     ]
    }
   ],
   "source": [
    "!sos run LDSC_DeepSea_Code.ipynb -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Train Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[train_model]\n",
    "\n",
    "bash: container='/mnt/mfs/statgen/Anmol/deepsea_latest.sif'\n",
    "\n",
    "    python3.7 /mnt/mfs/statgen/Anmol/training_files/tutorial/run_neuron_full_tutorial.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Make Full Annotation File Based on Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[make_annot]\n",
    "\n",
    "#path to feature list file\n",
    "parameter: feature_list = str\n",
    "#path to trained model location\n",
    "parameter: model = str\n",
    "#path to output directory\n",
    "parameter: output = str\n",
    "\n",
    "\n",
    "python3: container='/mnt/mfs/statgen/Anmol/deepsea_latest.sif'\n",
    "\n",
    "    from selene_sdk.utils import load_path\n",
    "    from selene_sdk.utils import parse_configs_and_run\n",
    "    from selene_sdk.predict import AnalyzeSequences\n",
    "    from selene_sdk.sequences import Genome\n",
    "    from selene_sdk.utils import load_features_list\n",
    "    from selene_sdk.utils import NonStrandSpecific\n",
    "    from selene_sdk.utils import DeeperDeepSEA\n",
    "    import glob\n",
    "    import os\n",
    "    distinct_features = load_features_list({feature_list})\n",
    "\n",
    "    model_predict = AnalyzeSequences(\n",
    "    NonStrandSpecific(DeeperDeepSEA(1000,{num_features})),\n",
    "    {model},\n",
    "    sequence_length=1000,\n",
    "    features=distinct_features,\n",
    "    reference_sequence=Genome(\"/mnt/mfs/statgen/Anmol/training_files/male.hg19.fasta\"),\n",
    "    use_cuda=False # update this to False if you do not have CUDA on your machine.\n",
    "    )\n",
    "\n",
    "    for i in range(1,22):\n",
    "        model_predict.variant_effect_prediction(\n",
    "        \"/mnt/mfs/statgen/Anmol/training_files/testing/1000G_chr_\"+str(i)+\".vcf\",\n",
    "        save_data=[\"abs_diffs\"],  # only want to save the absolute diff score data\n",
    "        output_dir={output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Format Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[format_annot]\n",
    "\n",
    "#path to tsv files directory\n",
    "parameter: tsv = path()\n",
    "#path to output file directory\n",
    "parameter: output = path()\n",
    "\n",
    "R: expand = \"${ }\", container=\"/mnt/mfs/statgen/Anmol/r-packages.sif\"\n",
    "    library(data.table)\n",
    "    library(tidyverse)\n",
    "    data = fread(paste0(\"${tsv}\",\"/tutorial_1000G_chr_\",22,\"_abs_diffs.tsv\"))\n",
    "    features = colnames(data)[9:ncol(data)]\n",
    "    features = data.frame(features)\n",
    "    features$encoding = paste0(\"feat_\",seq(1,nrow(features)))\n",
    "    fwrite(features,paste0(\"${output}\",\"/feature_encoding.txt\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    for (i in seq(1,22)){\n",
    "    data = fread(paste0(\"${tsv}\",\"/tutorial_1000G_chr_\",i,\"_abs_diffs.tsv\"))\n",
    "    data_2 = select(data,-seq(4,8))\n",
    "    base = data.frame(base=rep(1,nrow(data_2)))\n",
    "    fwrite(base,paste0(\"${output}\",\"/base_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    for (j in seq(4,ncol(data_2))){\n",
    "    data_3 = select(data_2,c(1,2,3,j))\n",
    "    colnames(data_3) = c(\"CHR\",\"BP\",\"SNP\",paste0(\"feat_\",j))\n",
    "    data_3 = setorder(data_3,BP)\n",
    "    data_3 = select(data_3,-c(\"CHR\",\"BP\",\"SNP\"))\n",
    "    fwrite(data_3,paste0(\"${output}\",\"/feat_\",j,\"_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Munge Summary Statistics (Option 1: No Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#This option is for when the summary statistic file does not contain a signed summary statistic (Z or Beta). \n",
    "#In this case,the program will calculate Z for you based on A1 being the risk allele\n",
    "[munge_sumstats_no_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: \n",
    "    python2 munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output} --a1-inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Munge Summary Statistics (Option 2: No Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This option is for when the summary statistic file does contain a signed summary statistic (Z or Beta)\n",
    "[munge_sumstats_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output = str\n",
    "\n",
    "bash: \n",
    "    python2 munge_sumstats.py --sumstats {sumst} --merge-alleles {alleles} --out {output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate LD Scores:\n",
    "\n",
    "**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[calc_ld_score]\n",
    "\n",
    "#Path to directory with bim files\n",
    "parameter: bim = path()\n",
    "#Path to directory with annotation files, output will appear here too. Make sure to remove the SNP, CHR, and BP columns from the annotation files if present before running.\n",
    "parameter: annot_files = path()\n",
    "#number of features\n",
    "parameter: num_features = int\n",
    "\n",
    "bash: \n",
    "   #echo {annot_files} > out.txt\n",
    "   for i in $(seq 1 {num_features});do for j in {1..22}; do python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --bfile {bim}/1000G.EUR.QC.${j} --l2 --ld-wind-cm 1 --annot {annot_files}/feat_${i}_chr_${j}.annot.gz --thin-annot --out {annot_files}/feat_${i}_chr_${j} --print-snps /mnt/mfs/statgen/Anmol/ldsc/tutorial_data/w_hm3.snplist/snplist.txt; done; done\n",
    "   for j in {1..22}; do python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --bfile {bim}/1000G.EUR.QC.${j} --l2 --ld-wind-cm 1 --annot {annot_files}/base_chr_${j}.annot.gz --thin-annot --out {annot_files}/base_chr_${j} --print-snps /mnt/mfs/statgen/Anmol/ldsc/tutorial_data/w_hm3.snplist/snplist.txt; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Convert LD Score SNPs to AD Summary Statistic Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[convert_ld_snps]\n",
    "\n",
    "#Path to directory with ld score files AND annotation files\n",
    "parameter: ld_scores = str\n",
    "\n",
    "parameter: num_features = int\n",
    "\n",
    "\n",
    "R: expand = \"${ }\", container=\"/mnt/mfs/statgen/Anmol/r-packages.sif\"\n",
    "    library(tidyverse)\n",
    "    #library(R.utils)\n",
    "    library(data.table)\n",
    "    for (i in seq(1,22)){\n",
    "      data = read.table(gzfile(paste0(\"${ld_scores}/base_chr_\",i,\".l2.ldscore.gz\")))\n",
    "      data_2 = fread(paste0(\"${ld_scores}/base_chr_\",i,\".l2.M_5_50\"))\n",
    "      data_3 = read.table(gzfile(paste0(\"${ld_scores}/base_chr_\",i,\".annot.gz\")))\n",
    "      data$SNP = paste0(data$CHR,\":\",data$BP)\n",
    "      fwrite(data,paste0(\"${ld_scores}/AD_base_chr_\",i,\".l2.ldscore.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      fwrite(data_2,paste0(\"${ld_scores}/AD_base_chr_\",i,\".l2.M_5_50\"),quote=F,sep=\"\\t\",row.names=F,col.names=F)\n",
    "      fwrite(data_3,paste0(\"${ld_scores}/AD_base_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      for (j in seq(1,${num_features})){\n",
    "      data = read.table(gzfile(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".l2.ldscore.gz\")))\n",
    "      data_2 = fread(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".l2.M_5_50\"))\n",
    "      data_3 = read.table(gzfile(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".annot.gz\")))\n",
    "      data$SNP = paste0(data$CHR,\":\",data$BP)\n",
    "      fwrite(data,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".l2.ldscore.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      fwrite(data_2,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".l2.M_5_50\"),quote=F,sep=\"\\t\",row.names=F,col.names=F)\n",
    "      fwrite(data_3,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    }\n",
    "    }\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate Functional Enrichment using Annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#Calculate Enrichment Scores for Functional Annotations\n",
    "\n",
    "[calc_enrichment]\n",
    "\n",
    "#Path to Summary statistics File\n",
    "parameter: sumstats = str\n",
    "#Path to Reference LD Scores Files (Base Annotation + Annotation you want to analyze, format like minimal working example)\n",
    "parameter: ref_ld = str\n",
    "#Path to LD Weight Files (Format like minimal working example)\n",
    "parameter: w_ld = str\n",
    "#path to frequency files (Format like minimal working example)\n",
    "parameter: frq_file = str\n",
    "#Output name\n",
    "parameter: output = str\n",
    "\n",
    "bash:\n",
    "    python2 ldsc.py --h2 {sumstats} --ref-ld-chr {ref_ld} --w-ld-chr {w_ld} --overlap-annot --frqfile-chr {frq_file} --out {output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
