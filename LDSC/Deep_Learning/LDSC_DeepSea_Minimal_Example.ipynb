{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Tutorial Workflow for LDSC with DeepSea Integration:\n",
    "\n",
    "This is the code to run the minimal working example for LDSC with DeepSea Integration. The code will train the deepsea model on the set of features provided using the .yml file on the google drive folder, get predictions on the reference genome from the trained model, and run LDSC on the resulting predictions to output enrichments. \n",
    "\n",
    "If you would like to use a different set of features or change training parameters, please edit the .yml file provided and everything else will still work.\n",
    "\n",
    "This is the command to run the Minimal Working Example:\n",
    "\n",
    "\n",
    "sos run LDSC_DeepSea_Code.ipynb --model /mnt/mfs/statgen/Anmol/training_files/tutorial/training_outputs/model --feature_list /mnt/mfs/statgen/Anmol/training_files/tutorial/tutorial_features.txt --output_tsv /mnt/mfs/statgen/Anmol/training_files/tutorial/testing --tsv /mnt/mfs/statgen/Anmol/training_files/tutorial/testing --annot_files /mnt/mfs/statgen/Anmol/training_files/tutorial/annot_files --sumst /mnt/mfs/statgen/Anmol/polyfun/Dey/PGCALZ2sumstatsExcluding23andMe.txt --output_sumst /mnt/mfs/statgen/Anmol/polyfun/Dey/2021.Updated.sumstats.gz --signed True --bim /mnt/mfs/statgen/Anmol/training_files/tutorial/plink_files --num_features 7 --ld_scores /mnt/mfs/statgen/Anmol/training_files/tutorial/annot_files --ctrl_sumstats /mnt/mfs/statgen/Anmol/polyfun/Dey/AMD.sumstats.gz --AD_sumstats /mnt/mfs/statgen/Anmol/polyfun/Dey/2021.Updated.sumstats.gz --w_ld_ctrl /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/tutorial_data/weights_hm3_no_hla/weights. --frq_file_ctrl /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/frq/1000G.EUR.QC. --w_ld_AD /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/tutorial_data/weights_hm3_no_hla/weights.2021. --frq_file_AD /mnt/mfs/statgen/Anmol/training_files/testing/ldsc/AD_Variants/frq/1000G.2021.EUR.QC. --ref_ld annot_files --pheno AMD\n",
    "\n",
    "## Command Interface:\n",
    "\n",
    "This is the list of commands and workflows with explanations for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LDSC_DeepSea_Minimal_Example.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  train_model\n",
      "  make_annot\n",
      "  format_annot\n",
      "  munge_sumstats_no_sign\n",
      "  munge_sumstats_sign\n",
      "  calc_ld_score\n",
      "  convert_ld_snps\n",
      "  calc_enrichment\n",
      "\n",
      "Sections\n",
      "  train_model:\n",
      "  make_annot:\n",
      "    Workflow Options:\n",
      "      --feature-list VAL (as str, required)\n",
      "                        path to feature list file\n",
      "      --model VAL (as str, required)\n",
      "                        path to trained model location\n",
      "      --output-tsv VAL (as str, required)\n",
      "                        path to output directory\n",
      "  format_annot:\n",
      "    Workflow Options:\n",
      "      --tsv . (as path)\n",
      "                        path to tsv files directory\n",
      "      --annot-files . (as path)\n",
      "                        path to output file directory\n",
      "  munge_sumstats_no_sign:\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output-sumst VAL (as str, required)\n",
      "                        path to output file\n",
      "      --[no-]signed (default to False)\n",
      "                        does summary statistic contain Z or Beta\n",
      "  munge_sumstats_sign:  This option is for when the summary statistic file does\n",
      "                        contain a signed summary statistic (Z or Beta)\n",
      "    Workflow Options:\n",
      "      --sumst VAL (as str, required)\n",
      "                        path to summary statistic file\n",
      "      --alleles 'w_hm3.snplist'\n",
      "                        path to Hapmap3 SNPs file, keep all columns (SNP, A1,\n",
      "                        and A2) for the munge_sumstats program\n",
      "      --output-sumst-2 VAL (as str, required)\n",
      "                        path to output file\n",
      "      --[no-]signed (default to False)\n",
      "                        does summary statistic contain Z or Beta\n",
      "  calc_ld_score:\n",
      "    Workflow Options:\n",
      "      --bim . (as path)\n",
      "                        Path to directory with bim files\n",
      "      --annot-files . (as path)\n",
      "                        Path to directory with annotation files, output will\n",
      "                        appear here too. Make sure to remove the SNP, CHR, and\n",
      "                        BP columns from the annotation files if present before\n",
      "                        running.\n",
      "      --num-features VAL (as int, required)\n",
      "                        number of features\n",
      "  convert_ld_snps:\n",
      "    Workflow Options:\n",
      "      --ld-scores VAL (as str, required)\n",
      "                        Path to directory with ld score files AND annotation\n",
      "                        files\n",
      "      --num-features VAL (as int, required)\n",
      "  calc_enrichment:\n",
      "    Workflow Options:\n",
      "      --ctrl-sumstats VAL (as str, required)\n",
      "                        Path to Control Summary statistics File\n",
      "      --AD-sumstats VAL (as str, required)\n",
      "                        Path to AD Summary statistics File\n",
      "      --ref-ld VAL (as str, required)\n",
      "                        Path to Reference LD Scores File Directory\n",
      "      --w-ld-ctrl VAL (as str, required)\n",
      "                        Path to LD Weight Files for Control Sumstats (Format\n",
      "                        like minimal working example)\n",
      "      --frq-file-ctrl VAL (as str, required)\n",
      "                        path to frequency files for Control Sumstats (Format\n",
      "                        like minimal working example)\n",
      "      --w-ld-AD VAL (as str, required)\n",
      "                        Path to LD Weight Files for AD Sumstats (Format like\n",
      "                        minimal working example)\n",
      "      --frq-file-AD VAL (as str, required)\n",
      "                        path to frequency files for AD Sumstats (Format like\n",
      "                        minimal working example)\n",
      "      --num-features VAL (as int, required)\n",
      "                        Number of Features\n",
      "      --pheno VAL (as str, required)\n",
      "                        Control Phenotype, For Output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sos run LDSC_DeepSea_Code.ipynb -h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Train Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[train_model]\n",
    "\n",
    "bash: container='/mnt/mfs/statgen/Anmol/deepsea_latest.sif'\n",
    "\n",
    "    python3.7 /mnt/mfs/statgen/Anmol/training_files/tutorial/run_neuron_full_tutorial.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Make Full Annotation File Based on Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Get Predictions for Features based on Trained Model\n",
    "\n",
    "\n",
    "[make_annot]\n",
    "\n",
    "#path to feature list file\n",
    "parameter: feature_list = str\n",
    "#path to trained model location\n",
    "parameter: model = str\n",
    "#path to output directory\n",
    "parameter: output_tsv = str\n",
    "\n",
    "\n",
    "python3: container='/mnt/mfs/statgen/Anmol/deepsea_latest.sif'\n",
    "\n",
    "    from selene_sdk.utils import load_path\n",
    "    from selene_sdk.utils import parse_configs_and_run\n",
    "    from selene_sdk.predict import AnalyzeSequences\n",
    "    from selene_sdk.sequences import Genome\n",
    "    from selene_sdk.utils import load_features_list\n",
    "    from selene_sdk.utils import NonStrandSpecific\n",
    "    from selene_sdk.utils import DeeperDeepSEA\n",
    "    import glob\n",
    "    import os\n",
    "    distinct_features = load_features_list({feature_list})\n",
    "\n",
    "    model_predict = AnalyzeSequences(\n",
    "    NonStrandSpecific(DeeperDeepSEA(1000,{num_features})),\n",
    "    {model}+\"/best_model.pth.tar\",\n",
    "    sequence_length=1000,\n",
    "    features=distinct_features,\n",
    "    reference_sequence=Genome(\"/mnt/mfs/statgen/Anmol/training_files/male.hg19.fasta\"),\n",
    "    use_cuda=False # update this to False if you do not have CUDA on your machine.\n",
    "    )\n",
    "\n",
    "    for i in range(1,23):\n",
    "        model_predict.variant_effect_prediction(\n",
    "        \"/mnt/mfs/statgen/Anmol/training_files/testing/1000G_chr_\"+str(i)+\".vcf\",\n",
    "        save_data=[\"abs_diffs\"],  # only want to save the absolute diff score data\n",
    "        output_dir={output})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Format Annotation File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Separate Annotation Files by Chromosome\n",
    "\n",
    "\n",
    "[format_annot]\n",
    "\n",
    "#path to tsv files directory\n",
    "parameter: tsv = path()\n",
    "#path to output file directory\n",
    "parameter: annot_files = path()\n",
    "\n",
    "R: expand = \"${ }\", container=\"/mnt/mfs/statgen/Anmol/r-packages.sif\"\n",
    "    library(data.table)\n",
    "    library(tidyverse)\n",
    "    data = fread(paste0(\"${tsv}\",\"/tutorial_1000G_chr_\",22,\"_abs_diffs.tsv\"))\n",
    "    features = colnames(data)[9:ncol(data)]\n",
    "    features = data.frame(features)\n",
    "    features$encoding = paste0(\"feat_\",seq(1,nrow(features)))\n",
    "    fwrite(features,paste0(\"${annot_files}\",\"/feature_encoding.txt\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    for (i in seq(1,22)){\n",
    "    data = fread(paste0(\"${tsv}\",\"/tutorial_1000G_chr_\",i,\"_abs_diffs.tsv\"))\n",
    "    data_2 = select(data,-seq(4,8))\n",
    "    base = data.frame(base=rep(1,nrow(data_2)))\n",
    "    fwrite(base,paste0(\"${annot_files}\",\"/base_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    for (j in seq(4,ncol(data_2))){\n",
    "    data_3 = select(data_2,c(1,2,3,j))\n",
    "    colnames(data_3) = c(\"CHR\",\"BP\",\"SNP\",paste0(\"feat_\",j))\n",
    "    data_3 = setorder(data_3,BP)\n",
    "    data_3 = select(data_3,-c(\"CHR\",\"BP\",\"SNP\"))\n",
    "    fwrite(data_3,paste0(\"${annot_files}\",\"/feat_\",j,\"_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Munge Summary Statistics (Option 1: No Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Option when Summary Statistic File does not contain a Z or Beta Column (Signed Summary Statistic)\n",
    "\n",
    "[munge_sumstats_no_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output_sumst = str\n",
    "#does summary statistic contain Z or Beta\n",
    "parameter: signed = False\n",
    "\n",
    "bash: expand = '${ }'\n",
    "   if [${signed}==True]\n",
    "       then\n",
    "           python2 /mnt/mfs/statgen/Anmol/ldsc/munge_sumstats.py --sumstats ${sumst} --merge-alleles ${alleles} --out ${output_sumst} --a1-inc\n",
    "       fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Munge Summary Statistics (Option 2: Contains Signed Summary Statistic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# This option is for when the summary statistic file does contain a signed summary statistic (Z or Beta)\n",
    "[munge_sumstats_sign]\n",
    "\n",
    "\n",
    "\n",
    "#path to summary statistic file\n",
    "parameter: sumst = str\n",
    "#path to Hapmap3 SNPs file, keep all columns (SNP, A1, and A2) for the munge_sumstats program\n",
    "parameter: alleles = \"w_hm3.snplist\"\n",
    "#path to output file\n",
    "parameter: output_sumst_2 = str\n",
    "#does summary statistic contain Z or Beta\n",
    "parameter: signed = False\n",
    "\n",
    "bash: expand = '${ }'\n",
    "    if [${signed}==False]\n",
    "        then\n",
    "            python2 /mnt/mfs/statgen/Anmol/ldsc/munge_sumstats.py --sumstats ${sumst} --merge-alleles ${alleles} --out ${output_sumst_2}\n",
    "        fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate LD Scores:\n",
    "\n",
    "**Make sure to delete SNP,CHR, and BP columns from annotation files if they are present otherwise this code will not work. Before deleting, if these columns are present, make sure that the annotation file is sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[calc_ld_score]\n",
    "\n",
    "#Path to directory with bim files\n",
    "parameter: bim = path()\n",
    "#Path to directory with annotation files, output will appear here too. Make sure to remove the SNP, CHR, and BP columns from the annotation files if present before running.\n",
    "parameter: annot_files = path()\n",
    "#number of features\n",
    "parameter: num_features = int\n",
    "\n",
    "bash: expand = '${ }'\n",
    "   #echo {annot_files} > out.txt\n",
    "   seq 1 ${num_features}| xargs -n 1 -I j -P 4 python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --bfile ${bim}/1000G.EUR.QC.22 --l2 --ld-wind-cm 1 --annot ${annot_files}/feat_j_chr_22.annot.gz --thin-annot --out ${annot_files}/feat_j_chr_22 --print-snps /mnt/mfs/statgen/Anmol/ldsc/tutorial_data/w_hm3.snplist/snplist.txt\n",
    "   seq 1 22| xargs -n 1 -I j -P 4 python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --bfile ${bim}/1000G.EUR.QC.j --l2 --ld-wind-cm 1 --annot ${annot_files}/base_chr_j.annot.gz --thin-annot --out ${annot_files}/base_chr_j --print-snps /mnt/mfs/statgen/Anmol/ldsc/tutorial_data/w_hm3.snplist/snplist.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Convert LD Score SNPs to AD Summary Statistic Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Convert SNP format in LD Score Files to CHR:BP to match with AD Summary Statistic Format\n",
    "\n",
    "\n",
    "[convert_ld_snps]\n",
    "\n",
    "#Path to directory with ld score files AND annotation files\n",
    "parameter: ld_scores = str\n",
    "\n",
    "parameter: num_features = int\n",
    "\n",
    "\n",
    "R: expand = \"${ }\", container=\"/mnt/mfs/statgen/Anmol/r-packages.sif\"\n",
    "    library(tidyverse)\n",
    "    #library(R.utils)\n",
    "    library(data.table)\n",
    "    for (i in seq(1,22)){\n",
    "      data = read.table(gzfile(paste0(\"${ld_scores}/base_chr_\",i,\".l2.ldscore.gz\")),header=T)\n",
    "      data_2 = fread(paste0(\"${ld_scores}/base_chr_\",i,\".l2.M_5_50\"))\n",
    "      data_3 = read.table(gzfile(paste0(\"${ld_scores}/base_chr_\",i,\".annot.gz\")),header=T)\n",
    "      data$SNP = paste0(data$CHR,\":\",data$BP)\n",
    "      fwrite(data,paste0(\"${ld_scores}/AD_base_chr_\",i,\".l2.ldscore.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      fwrite(data_2,paste0(\"${ld_scores}/AD_base_chr_\",i,\".l2.M_5_50\"),quote=F,sep=\"\\t\",row.names=F,col.names=F)\n",
    "      fwrite(data_3,paste0(\"${ld_scores}/AD_base_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      for (j in seq(1,${num_features})){\n",
    "      data = read.table(gzfile(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".l2.ldscore.gz\")),header=T)\n",
    "      data_2 = fread(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".l2.M_5_50\"))\n",
    "      data_3 = read.table(gzfile(paste0(\"${ld_scores}/feat_\",j,\"_chr_\",i,\".annot.gz\")),header=T)\n",
    "      data$SNP = paste0(data$CHR,\":\",data$BP)\n",
    "      fwrite(data,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".l2.ldscore.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "      fwrite(data_2,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".l2.M_5_50\"),quote=F,sep=\"\\t\",row.names=F,col.names=F)\n",
    "      fwrite(data_3,paste0(\"${ld_scores}/AD_feat_\",j,\"_chr_\",i,\".annot.gz\"),quote=F,sep=\"\\t\",row.names=F,col.names=T)\n",
    "    }\n",
    "    }\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python 3 (ipykernel)"
   },
   "source": [
    "## Calculate Functional Enrichment using Annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "\n",
    "[calc_enrichment]\n",
    "\n",
    "#Path to Control Summary statistics File\n",
    "parameter: ctrl_sumstats = str\n",
    "#Path to AD Summary statistics File\n",
    "parameter: AD_sumstats = str\n",
    "#Path to Reference LD Scores File Directory \n",
    "parameter: ref_ld = str\n",
    "#Path to LD Weight Files for Control Sumstats (Format like minimal working example)\n",
    "parameter: w_ld_ctrl = str\n",
    "#path to frequency files for Control Sumstats (Format like minimal working example)\n",
    "parameter: frq_file_ctrl = str\n",
    "#Path to LD Weight Files for AD Sumstats (Format like minimal working example)\n",
    "parameter: w_ld_AD = str\n",
    "#path to frequency files for AD Sumstats (Format like minimal working example)\n",
    "parameter: frq_file_AD = str\n",
    "#Number of Features\n",
    "parameter: num_features = int \n",
    "#Control Phenotype, For Output\n",
    "parameter: pheno = str\n",
    "\n",
    "bash: expand = '${ }'\n",
    "    seq 1 ${num_features}| xargs -n 1 -I j -P 4 python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --h2 ${ctrl_sumstats} --ref-ld-chr ${ref_ld}/base_chr_,${ref_ld}/feat_j_chr_ --w-ld-chr ${w_ld_ctrl} --overlap-annot --frqfile-chr ${frq_file_ctrl} --out ${ref_ld}/${pheno}_feat_j\n",
    "    seq 1 ${num_features}| xargs -n 1 -I j -P 4 python2 /mnt/mfs/statgen/Anmol/ldsc/ldsc.py --h2 ${AD_sumstats} --ref-ld-chr ${ref_ld}/AD_base_chr_,${ref_ld}/AD_feat_j_chr_ --w-ld-chr ${w_ld_AD} --overlap-annot --frqfile-chr ${frq_file_AD} --out ${ref_ld}/AD_feat_j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
